{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallpaz/drl/blob/main/notebooks/pratica_gymnasium.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo deste projeto é implementar um ambiente de simulação no framework Gym para resolver um problema específico. Neste problema, há uma coluna denominada \"Random\" contendo 10 posições, cada uma com um valor aleatório entre 1 e 100 (distribuição uniforme). Além disso, há um campo chamado \"Target\" que recebe um valor aleatório entre 1 e 100 (distribuição uniforme)."
      ],
      "metadata": {
        "id": "fBdOIgTkto0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code"
      ],
      "metadata": {
        "id": "JfEJCy5hv6NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A missão do agente é selecionar até 5 posições da coluna \"Random\", uma de cada vez, de modo que a soma dos valores dessas 5 posições alcance o valor do campo \"Target\", indicando o fim do episódio. A cada seleção que o agente aposta em fazer, as posições da coluna \"Random\" são sorteadas novamente, exceto aquelas que foram previamente escolhidas pelo agente. As posições selecionadas recebem um sinalizador booleano, indicando que não podem mais ser escolhidas, e seus valores permanecem fixos. É importante destacar que o agente só pode \"olhar\" para uma posição de cada vez da coluna \"Random\" e que ele poderá executar no máximo 10 ciclos de varredura em \"Random\". Os ciclos ocorrem dentro de um while done, onde done é: Ou a soma de target foi satisfeita ou o número de tentativas ou ciclos foi superado.\n",
        "\n",
        "Implementação:\n",
        "1 - Criação do Ambiente de simulação utilizando o framework Gym.\n",
        "2 - Definição inicial dos hiperparâmetros.\n",
        "3 - Arquitetura da Rede Neural com Tensorflow.\n",
        "4 - Treinamento do Agente.\n",
        "5 - Teste e Demonstração do Agente Maduro."
      ],
      "metadata": {
        "id": "Hec3FghOv4Q2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MH3CqpCtllq"
      },
      "outputs": [],
      "source": [
        "# code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cobrar para que os alunos alterem o código para que o seguinte problema:\n",
        "Neste novo problema existirão duas colunas: \"Random1\" e \"Random2\".\n",
        "O agente poderá \"olhar\" para uma posição de cada coluna ao mesmo tempo.\n",
        "O agente deve encontrar o par de posições provenientes de \"Random1\" e \"Random2\" que multiplicados, sejam somados a um acumulador visando atingir o \"Target\". A cada par escolhido, \"Random1\" e \"Random2\" são atualizados."
      ],
      "metadata": {
        "id": "8_yZFxwmuTcx"
      }
    }
  ]
}