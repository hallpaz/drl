{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hallpaz/drl/blob/main/notebooks/alternative_PPO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBdOIgTkto0S"
      },
      "source": [
        "O objetivo deste projeto é implementar um ambiente de simulação no framework Gym para resolver um problema específico. Neste problema, há uma coluna denominada \"Random\" contendo 50 posições, cada uma com um valor aleatório entre 1 e 100 (distribuição uniforme). Além disso, há um campo chamado \"Target\" que recebe um valor aleatório entre 1 e 100 (distribuição uniforme)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbOkD2Hl23iW"
      },
      "source": [
        "A missão do agente é selecionar até 5 posições da coluna \"Random\", uma de cada vez, de modo que a soma dos valores dessas 5 posições alcance o valor do campo \"Target\", indicando o fim do episódio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeb-XzPe6wZt",
        "outputId": "c48345a1-4d91-468f-d859-2029ba09aa2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.10.0)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium)\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gymnasium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hec3FghOv4Q2"
      },
      "source": [
        "É importante destacar que o agente só pode \"olhar\" para uma posição de cada vez da coluna \"Random\".\n",
        "\n",
        "Um episódio é finalizado se a soma de target foi satisfeita ou todas os valores na coluna Random foram vistos ao menos 1 vez.\n",
        "\n",
        "Implementação:\n",
        "1 - Criação do Ambiente de simulação utilizando o framework Gym.\n",
        "2 - Definição inicial dos hiperparâmetros.\n",
        "3 - Arquitetura da Rede Neural com Tensorflow.\n",
        "4 - Treinamento do Agente.\n",
        "5 - Teste e Demonstração do Agente Maduro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JfEJCy5hv6NP"
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CfruZQklHiMm"
      },
      "outputs": [],
      "source": [
        "COMBINE = 1\n",
        "DONT_COMBINE = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7ofsj8rc7BPk"
      },
      "outputs": [],
      "source": [
        "class MatchingEnv(gym.Env):\n",
        "  def __init__(self, options_size=50, target_size=1, options_limit=5, max_value=100):\n",
        "    self.options_size = options_size\n",
        "    self.target_size = target_size\n",
        "    self.options_limit = options_limit\n",
        "    self.max_value = max_value\n",
        "    self.action_space = [0, 1]\n",
        "\n",
        "    self.reset()\n",
        "\n",
        "  def reset(self):\n",
        "    self.options = np.random.randint(1, self.max_value + 1, self.options_size)\n",
        "    self.target = np.random.randint(1, self.max_value + 1, self.target_size)\n",
        "    self.current_option_index = 0\n",
        "    self.current_target_index = 0\n",
        "    self.selected = []\n",
        "\n",
        "    return (self.options[self.current_option_index],\n",
        "            self.target[self.current_target_index],\n",
        "            self.options_size - 1,\n",
        "            len(self.selected))\n",
        "\n",
        "  def step(self, action):\n",
        "    done = False\n",
        "    reward = 0\n",
        "    if action == COMBINE:\n",
        "      current_value = self.options[self.current_option_index]\n",
        "      self.selected.append(current_value)\n",
        "      # avança para o próximo valor\n",
        "      self.current_option_index += 1\n",
        "      # calcula o quanto falta em relação ao target\n",
        "      # self.target[self.current_target_index] -= current_value\n",
        "      remaining_value = self.target[self.current_target_index] - sum(self.selected)\n",
        "      # quantos passos ainda faltam\n",
        "      remaining_steps = self.options_size - self.current_option_index - 1\n",
        "\n",
        "      if remaining_value > 0:\n",
        "        reward = current_value\n",
        "      elif remaining_value == 0:\n",
        "        reward = 100 * 10**(self.options_limit - len(self.selected))\n",
        "        done = True\n",
        "      else:\n",
        "        reward = -sum(self.selected)\n",
        "        done = True\n",
        "\n",
        "    else:\n",
        "      self.current_option_index += 1\n",
        "      # calcula o quanto falta em relação ao target\n",
        "      remaining_value = self.target[self.current_target_index] - sum(self.selected)\n",
        "      # quantos passos ainda faltam\n",
        "      remaining_steps = self.options_size - self.current_option_index - 1\n",
        "\n",
        "    if remaining_steps < 0 and not self.selected:\n",
        "      reward = -100\n",
        "\n",
        "    if remaining_steps < 0 or len(self.selected) >= self.options_limit or reward < 0:\n",
        "      done = True\n",
        "\n",
        "    next_state = (self.options[self.current_option_index % self.options_size],\n",
        "                remaining_value,\n",
        "                remaining_steps,\n",
        "                len(self.selected))\n",
        "    print(next_state)\n",
        "    return next_state, reward, done, {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OX47A_Ie5m6D"
      },
      "outputs": [],
      "source": [
        "env = MatchingEnv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "9MH3CqpCtllq"
      },
      "outputs": [],
      "source": [
        "class Critic(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.d1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.d2 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.v = tf.keras.layers.Dense(1, activation = None)\n",
        "\n",
        "  def call(self, input_data):\n",
        "    x = self.d1(input_data)\n",
        "    x = self.d2(x)\n",
        "    v = self.v(x)\n",
        "    return v\n",
        "\n",
        "\n",
        "class Actor(tf.keras.Model):\n",
        "  def __init__(self, n_actions=2):\n",
        "    super().__init__()\n",
        "    self.d1 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.d2 = tf.keras.layers.Dense(256, activation='relu')\n",
        "    self.a = tf.keras.layers.Dense(n_actions, activation='softmax')\n",
        "\n",
        "  def call(self, input_data):\n",
        "    x = self.d1(input_data)\n",
        "    x = self.d2(x)\n",
        "    a = self.a(x)\n",
        "    return a"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Code reference: https://medium.com/@sthanikamsanthosh1994/reinforcement-learning-part-8-proximal-policy-optimization-ppo-for-trading-9f1c3431f27d\n",
        "class PPOMemory:\n",
        "    def __init__(self, batch_size):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.vals = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def generate_batches(self):\n",
        "        n_states = len(self.states)\n",
        "        batch_start = np.arange(0, n_states, self.batch_size)\n",
        "        indices = np.arange(n_states, dtype=np.int64)\n",
        "        np.random.shuffle(indices)\n",
        "        batches = [indices[i:i+self.batch_size] for i in batch_start]\n",
        "\n",
        "        return np.array(self.states),\\\n",
        "            np.array(self.actions),\\\n",
        "            np.array(self.probs),\\\n",
        "            np.array(self.vals),\\\n",
        "            np.array(self.rewards),\\\n",
        "            np.array(self.dones),\\\n",
        "            batches\n",
        "\n",
        "    def store_memory(self, state, action, probs, vals, reward, done):\n",
        "        self.states.append(state)\n",
        "        self.actions.append(action)\n",
        "        self.probs.append(probs)\n",
        "        self.vals.append(vals)\n",
        "        self.rewards.append(reward)\n",
        "        self.dones.append(done)\n",
        "\n",
        "    def clear_memory(self):\n",
        "        self.states = []\n",
        "        self.probs = []\n",
        "        self.actions = []\n",
        "        self.rewards = []\n",
        "        self.dones = []\n",
        "        self.vals = []"
      ],
      "metadata": {
        "id": "a_pkBFIBOZx3"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "tTeL5mYU05fh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-SNatRFW4Nqv"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "  def __init__(self, n_actions, gamma=0.99, alpha=0.0003,\n",
        "                gae_lambda=0.95, policy_clip=0.2, batch_size=64,\n",
        "                n_epochs=10, chkpt_dir='models/'):\n",
        "      self.gamma = gamma\n",
        "      self.policy_clip = policy_clip\n",
        "      self.n_epochs = n_epochs\n",
        "      self.gae_lambda = gae_lambda\n",
        "      self.chkpt_dir = chkpt_dir\n",
        "\n",
        "      self.actor = Actor(n_actions)\n",
        "      self.actor.compile(optimizer=Adam(learning_rate=alpha))\n",
        "      self.critic = Critic()\n",
        "      self.critic.compile(optimizer=Adam(learning_rate=alpha))\n",
        "      self.memory = PPOMemory(batch_size)\n",
        "\n",
        "  def store_transition(self, state, action, probs, vals, reward, done):\n",
        "      self.memory.store_memory(state, action, probs, vals, reward, done)\n",
        "\n",
        "  def save_models(self):\n",
        "      print('... saving models ...')\n",
        "      self.actor.save(self.chkpt_dir + 'actor')\n",
        "      self.critic.save(self.chkpt_dir + 'critic')\n",
        "\n",
        "  def load_models(self):\n",
        "      print('... loading models ...')\n",
        "      self.actor = keras.models.load_model(self.chkpt_dir + 'actor')\n",
        "      self.critic = keras.models.load_model(self.chkpt_dir + 'critic')\n",
        "\n",
        "  def choose_action(self, observation):\n",
        "      state = tf.convert_to_tensor([observation])\n",
        "\n",
        "      probs = self.actor(state)\n",
        "      dist = tfp.distributions.Categorical(probs)\n",
        "      action = dist.sample()\n",
        "      log_prob = dist.log_prob(action)\n",
        "      value = self.critic(state)\n",
        "\n",
        "      action = action.numpy()[0]\n",
        "      value = value.numpy()[0]\n",
        "      log_prob = log_prob.numpy()[0]\n",
        "\n",
        "      return action, log_prob, value\n",
        "\n",
        "  def learn(self):\n",
        "      for _ in range(self.n_epochs):\n",
        "          state_arr, action_arr, old_prob_arr, vals_arr,\\\n",
        "              reward_arr, dones_arr, batches = \\\n",
        "              self.memory.generate_batches()\n",
        "\n",
        "          values = vals_arr\n",
        "          advantage = np.zeros(len(reward_arr), dtype=np.float32)\n",
        "\n",
        "          for t in range(len(reward_arr)-1):\n",
        "              discount = 1\n",
        "              a_t = 0\n",
        "              for k in range(t, len(reward_arr)-1):\n",
        "                  a_t += discount*(reward_arr[k] + self.gamma*values[k+1] * (\n",
        "                      1-int(dones_arr[k])) - values[k])\n",
        "                  discount *= self.gamma*self.gae_lambda\n",
        "              advantage[t] = a_t\n",
        "\n",
        "          for batch in batches:\n",
        "              with tf.GradientTape(persistent=True) as tape:\n",
        "                  states = tf.convert_to_tensor(state_arr[batch])\n",
        "                  old_probs = tf.convert_to_tensor(old_prob_arr[batch])\n",
        "                  actions = tf.convert_to_tensor(action_arr[batch])\n",
        "\n",
        "                  probs = self.actor(states)\n",
        "                  dist = tfp.distributions.Categorical(probs)\n",
        "                  new_probs = dist.log_prob(actions)\n",
        "\n",
        "                  critic_value = self.critic(states)\n",
        "\n",
        "                  critic_value = tf.squeeze(critic_value, 1)\n",
        "\n",
        "                  prob_ratio = tf.math.exp(new_probs - old_probs)\n",
        "                  weighted_probs = advantage[batch] * prob_ratio\n",
        "                  clipped_probs = tf.clip_by_value(prob_ratio,\n",
        "                                                    1-self.policy_clip,\n",
        "                                                    1+self.policy_clip)\n",
        "                  weighted_clipped_probs = clipped_probs * advantage[batch]\n",
        "                  actor_loss = -tf.math.minimum(weighted_probs,\n",
        "                                                weighted_clipped_probs)\n",
        "                  actor_loss = tf.math.reduce_mean(actor_loss)\n",
        "\n",
        "                  returns = advantage[batch] + values[batch]\n",
        "                  critic_loss = keras.losses.MSE(critic_value, returns)\n",
        "\n",
        "              actor_params = self.actor.trainable_variables\n",
        "              actor_grads = tape.gradient(actor_loss, actor_params)\n",
        "              critic_params = self.critic.trainable_variables\n",
        "              critic_grads = tape.gradient(critic_loss, critic_params)\n",
        "              self.actor.optimizer.apply_gradients(\n",
        "                      zip(actor_grads, actor_params))\n",
        "              self.critic.optimizer.apply_gradients(\n",
        "                      zip(critic_grads, critic_params))\n",
        "\n",
        "      self.memory.clear_memory()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DXPOYtHuOG1Y"
      },
      "outputs": [],
      "source": [
        "agent = Agent(2)\n",
        "steps = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kraOGGtx4PQU",
        "outputId": "5cb365a8-ea22-479a-c92c-14ae408cb0df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 84, 48, 0)\n",
            "(41, 73, 47, 1)\n",
            "(46, 32, 46, 2)\n",
            "(71, 32, 45, 2)\n",
            "(42, 32, 44, 2)\n",
            "(4, -10, 43, 3)\n",
            "episode 0 score -42.0 avg score -42.0 time_steps 6 learning_steps 0\n",
            "(57, 55, 48, 0)\n",
            "(65, -2, 47, 1)\n",
            "episode 1 score -57.0 avg score -49.5 time_steps 8 learning_steps 0\n",
            "(89, 1, 48, 0)\n",
            "(69, -88, 47, 1)\n",
            "episode 2 score -89.0 avg score -62.7 time_steps 10 learning_steps 0\n",
            "(78, 76, 48, 0)\n",
            "(44, 76, 47, 0)\n",
            "(62, 76, 46, 0)\n",
            "(75, 76, 45, 0)\n",
            "(65, 76, 44, 0)\n",
            "(95, 76, 43, 0)\n",
            "(13, 76, 42, 0)\n",
            "(68, 76, 41, 0)\n",
            "(35, 8, 40, 1)\n",
            "(43, -27, 39, 2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "episode 3 score -35.0 avg score -55.8 time_steps 20 learning_steps 1\n",
            "(43, 72, 48, 0)\n",
            "(60, 72, 47, 0)\n",
            "(49, 12, 46, 1)\n",
            "(23, 12, 45, 1)\n",
            "(18, 12, 44, 1)\n",
            "(2, 12, 43, 1)\n",
            "(47, 12, 42, 1)\n",
            "(3, 12, 41, 1)\n",
            "(77, 12, 40, 1)\n",
            "(81, 12, 39, 1)\n",
            "(15, 12, 38, 1)\n",
            "(62, -3, 37, 2)\n",
            "episode 4 score -15.0 avg score -47.6 time_steps 32 learning_steps 1\n",
            "(47, 83, 48, 0)\n",
            "(37, 83, 47, 0)\n",
            "(32, 83, 46, 0)\n",
            "(86, 51, 45, 1)\n",
            "(69, 51, 44, 1)\n",
            "(70, 51, 43, 1)\n",
            "(53, 51, 42, 1)\n",
            "(7, -2, 41, 2)\n",
            "episode 5 score -53.0 avg score -48.5 time_steps 40 learning_steps 2\n",
            "(9, 57, 48, 0)\n",
            "(6, 57, 47, 0)\n",
            "(31, 51, 46, 1)\n",
            "(44, 51, 45, 1)\n",
            "(40, 51, 44, 1)\n",
            "(38, 51, 43, 1)\n",
            "(85, 51, 42, 1)\n",
            "(2, 51, 41, 1)\n",
            "(30, 49, 40, 2)\n",
            "(13, 49, 39, 2)\n",
            "(45, 36, 38, 3)\n",
            "(84, 36, 37, 3)\n",
            "(88, 36, 36, 3)\n",
            "(88, -52, 35, 4)\n",
            "episode 6 score -88.0 avg score -54.1 time_steps 54 learning_steps 2\n",
            "(44, 98, 48, 0)\n",
            "(28, 98, 47, 0)\n",
            "(61, 98, 46, 0)\n",
            "(28, 98, 45, 0)\n",
            "(51, 70, 44, 1)\n",
            "(79, 70, 43, 1)\n",
            "(100, -9, 42, 2)\n",
            "episode 7 score -79.0 avg score -57.2 time_steps 61 learning_steps 3\n",
            "(46, 66, 48, 0)\n",
            "(6, 66, 47, 0)\n",
            "(87, 66, 46, 0)\n",
            "(40, -21, 45, 1)\n",
            "episode 8 score -87.0 avg score -60.6 time_steps 65 learning_steps 3\n",
            "(85, 20, 48, 0)\n",
            "(29, 20, 47, 0)\n",
            "(81, 20, 46, 0)\n",
            "(87, 20, 45, 0)\n",
            "(69, 20, 44, 0)\n",
            "(43, 20, 43, 0)\n",
            "(86, -23, 42, 1)\n",
            "episode 9 score -43.0 avg score -58.8 time_steps 72 learning_steps 3\n",
            "(2, 24, 48, 0)\n",
            "(21, 24, 47, 0)\n",
            "(8, 3, 46, 1)\n",
            "(31, 3, 45, 1)\n",
            "(40, 3, 44, 1)\n",
            "(90, 3, 43, 1)\n",
            "(79, -87, 42, 2)\n",
            "episode 10 score -90.0 avg score -61.6 time_steps 79 learning_steps 3\n",
            "(22, 93, 48, 0)\n",
            "(37, 93, 47, 0)\n",
            "(47, 56, 46, 1)\n",
            "(83, 9, 45, 2)\n",
            "(42, -74, 44, 3)\n",
            "episode 11 score -83.0 avg score -63.4 time_steps 84 learning_steps 4\n",
            "(85, 52, 48, 1)\n",
            "(97, -33, 47, 2)\n",
            "episode 12 score -85.0 avg score -65.1 time_steps 86 learning_steps 4\n",
            "(51, -42, 48, 1)\n",
            "episode 13 score -72.0 avg score -65.6 time_steps 87 learning_steps 4\n",
            "(75, -68, 48, 1)\n",
            "episode 14 score -73.0 avg score -66.1 time_steps 88 learning_steps 4\n",
            "(41, 82, 48, 0)\n",
            "(40, 82, 47, 0)\n",
            "(20, 82, 46, 0)\n",
            "(82, 82, 45, 0)\n",
            "(15, 82, 44, 0)\n",
            "(93, 82, 43, 0)\n",
            "(75, 82, 42, 0)\n",
            "(52, 7, 41, 1)\n",
            "(5, 7, 40, 1)\n",
            "(55, 2, 39, 2)\n",
            "(85, -53, 38, 3)\n",
            "episode 15 score -55.0 avg score -65.4 time_steps 99 learning_steps 4\n",
            "(86, -25, 48, 1)\n",
            "episode 16 score -98.0 avg score -67.3 time_steps 100 learning_steps 5\n",
            "(63, -73, 48, 1)\n",
            "episode 17 score -78.0 avg score -67.9 time_steps 101 learning_steps 5\n",
            "(68, 51, 48, 0)\n",
            "(72, 51, 47, 0)\n",
            "(16, -21, 46, 1)\n",
            "episode 18 score -72.0 avg score -68.1 time_steps 104 learning_steps 5\n",
            "(65, -83, 48, 1)\n",
            "episode 19 score -88.0 avg score -69.1 time_steps 105 learning_steps 5\n",
            "(76, 50, 48, 0)\n",
            "(40, 50, 47, 0)\n",
            "(46, 50, 46, 0)\n",
            "(21, 4, 45, 1)\n",
            "(64, 4, 44, 1)\n",
            "(75, -60, 43, 2)\n",
            "episode 20 score -64.0 avg score -68.9 time_steps 111 learning_steps 5\n",
            "(95, 48, 48, 0)\n",
            "(90, 48, 47, 0)\n",
            "(100, 48, 46, 0)\n",
            "(72, 48, 45, 0)\n",
            "(37, -24, 44, 1)\n",
            "episode 21 score -72.0 avg score -69.0 time_steps 116 learning_steps 5\n",
            "(32, 67, 48, 0)\n",
            "(35, 35, 47, 1)\n",
            "(16, 35, 46, 1)\n",
            "(14, 35, 45, 1)\n",
            "(8, 35, 44, 1)\n",
            "(85, 35, 43, 1)\n",
            "(21, 35, 42, 1)\n",
            "(94, 35, 41, 1)\n",
            "(68, 35, 40, 1)\n",
            "(75, 35, 39, 1)\n",
            "(32, 35, 38, 1)\n",
            "(12, 35, 37, 1)\n",
            "(61, 35, 36, 1)\n",
            "(46, 35, 35, 1)\n",
            "(17, -11, 34, 2)\n",
            "episode 22 score -46.0 avg score -68.0 time_steps 131 learning_steps 6\n",
            "(35, 99, 48, 0)\n",
            "(38, 99, 47, 0)\n",
            "(96, 99, 46, 0)\n",
            "(61, 99, 45, 0)\n",
            "(48, 99, 44, 0)\n",
            "(33, 51, 43, 1)\n",
            "(96, 51, 42, 1)\n",
            "(25, -45, 41, 2)\n",
            "episode 23 score -96.0 avg score -69.2 time_steps 139 learning_steps 6\n",
            "(26, 82, 48, 0)\n",
            "(48, 56, 47, 1)\n",
            "(81, 56, 46, 1)\n",
            "(45, -25, 45, 2)\n",
            "episode 24 score -81.0 avg score -69.6 time_steps 143 learning_steps 7\n",
            "(34, 69, 48, 0)\n",
            "(39, 35, 47, 1)\n",
            "(81, 35, 46, 1)\n",
            "(5, 35, 45, 1)\n",
            "(68, 35, 44, 1)\n",
            "(65, -33, 43, 2)\n",
            "episode 25 score -68.0 avg score -69.6 time_steps 149 learning_steps 7\n",
            "(91, 62, 48, 0)\n",
            "(97, 62, 47, 0)\n",
            "(32, 62, 46, 0)\n",
            "(98, 30, 45, 1)\n",
            "(4, -68, 44, 2)\n",
            "episode 26 score -98.0 avg score -70.6 time_steps 154 learning_steps 7\n",
            "(29, 73, 48, 0)\n",
            "(45, 73, 47, 0)\n",
            "(45, 73, 46, 0)\n",
            "(55, 73, 45, 0)\n",
            "(29, 73, 44, 0)\n",
            "(36, 73, 43, 0)\n",
            "(50, 37, 42, 1)\n",
            "(16, 37, 41, 1)\n",
            "(6, 37, 40, 1)\n",
            "(3, 37, 39, 1)\n",
            "(15, 34, 38, 2)\n",
            "(9, 19, 37, 3)\n",
            "(42, 19, 36, 3)\n",
            "(76, 19, 35, 3)\n",
            "(76, 19, 34, 3)\n",
            "(60, 19, 33, 3)\n",
            "(25, -41, 32, 4)\n",
            "episode 27 score -60.0 avg score -70.2 time_steps 171 learning_steps 8\n",
            "(23, 93, 48, 0)\n",
            "(40, 93, 47, 0)\n",
            "(76, 53, 46, 1)\n",
            "(32, 53, 45, 1)\n",
            "(58, 53, 44, 1)\n",
            "(27, 53, 43, 1)\n",
            "(58, 53, 42, 1)\n",
            "(74, 53, 41, 1)\n",
            "(55, 53, 40, 1)\n",
            "(93, 53, 39, 1)\n",
            "(100, -40, 38, 2)\n",
            "episode 28 score -93.0 avg score -71.0 time_steps 182 learning_steps 9\n",
            "(19, 34, 48, 0)\n",
            "(88, 34, 47, 0)\n",
            "(60, 34, 46, 0)\n",
            "(37, -26, 45, 1)\n",
            "episode 29 score -60.0 avg score -70.7 time_steps 186 learning_steps 9\n",
            "(1, 89, 48, 0)\n",
            "(84, 89, 47, 0)\n",
            "(3, 5, 46, 1)\n",
            "(60, 5, 45, 1)\n",
            "(13, 5, 44, 1)\n",
            "(91, -8, 43, 2)\n",
            "episode 30 score -13.0 avg score -68.8 time_steps 192 learning_steps 9\n",
            "(94, 7, 48, 0)\n",
            "(8, 7, 47, 0)\n",
            "(28, -1, 46, 1)\n",
            "episode 31 score -8.0 avg score -66.9 time_steps 195 learning_steps 9\n",
            "(50, 91, 48, 0)\n",
            "(29, 91, 47, 0)\n",
            "(85, 91, 46, 0)\n",
            "(65, 6, 45, 1)\n",
            "(90, 6, 44, 1)\n",
            "(23, -84, 43, 2)\n",
            "episode 32 score -90.0 avg score -67.6 time_steps 201 learning_steps 10\n",
            "(7, 54, 48, 1)\n",
            "(98, 54, 47, 1)\n",
            "(40, 54, 46, 1)\n",
            "(54, 54, 45, 1)\n",
            "(22, 54, 44, 1)\n",
            "(3, 54, 43, 1)\n",
            "(74, 54, 42, 1)\n",
            "(10, -20, 41, 2)\n",
            "episode 33 score -74.0 avg score -67.8 time_steps 209 learning_steps 10\n",
            "(24, -2, 48, 1)\n",
            "episode 34 score -98.0 avg score -68.7 time_steps 210 learning_steps 10\n",
            "(30, 10, 48, 0)\n",
            "(41, -20, 47, 1)\n",
            "episode 35 score -30.0 avg score -67.6 time_steps 212 learning_steps 10\n",
            "(38, 31, 48, 1)\n",
            "(74, 31, 47, 1)\n",
            "(91, 31, 46, 1)\n",
            "(81, 31, 45, 1)\n",
            "(64, 31, 44, 1)\n",
            "(57, -33, 43, 2)\n",
            "episode 36 score -64.0 avg score -67.5 time_steps 218 learning_steps 10\n",
            "(3, 55, 48, 1)\n",
            "(48, 52, 47, 2)\n",
            "(16, 52, 46, 2)\n",
            "(46, 52, 45, 2)\n",
            "(88, 52, 44, 2)\n",
            "(2, 52, 43, 2)\n",
            "(33, 52, 42, 2)\n",
            "(43, 52, 41, 2)\n",
            "(78, 52, 40, 2)\n",
            "(20, -26, 39, 3)\n",
            "episode 37 score -78.0 avg score -67.8 time_steps 228 learning_steps 11\n",
            "(85, 37, 48, 1)\n",
            "(92, -48, 47, 2)\n",
            "episode 38 score -85.0 avg score -68.2 time_steps 230 learning_steps 11\n",
            "(56, -61, 48, 1)\n",
            "episode 39 score -95.0 avg score -68.9 time_steps 231 learning_steps 11\n",
            "(28, -17, 48, 1)\n",
            "episode 40 score -63.0 avg score -68.7 time_steps 232 learning_steps 11\n",
            "(84, 58, 48, 0)\n",
            "(52, 58, 47, 0)\n",
            "(60, 58, 46, 0)\n",
            "(43, 58, 45, 0)\n",
            "(68, 58, 44, 0)\n",
            "(45, 58, 43, 0)\n",
            "(16, 58, 42, 0)\n",
            "(22, 42, 41, 1)\n",
            "(95, 42, 40, 1)\n",
            "(2, -53, 39, 2)\n",
            "episode 41 score -95.0 avg score -69.4 time_steps 242 learning_steps 12\n",
            "(97, 86, 48, 0)\n",
            "(97, 86, 47, 0)\n",
            "(46, 86, 46, 0)\n",
            "(4, 86, 45, 0)\n",
            "(80, 86, 44, 0)\n",
            "(14, 86, 43, 0)\n",
            "(43, 72, 42, 1)\n",
            "(44, 72, 41, 1)\n",
            "(77, 72, 40, 1)\n",
            "(26, 72, 39, 1)\n",
            "(57, 72, 38, 1)\n",
            "(31, 72, 37, 1)\n",
            "(42, 72, 36, 1)\n",
            "(26, 30, 35, 2)\n",
            "(68, 4, 34, 3)\n",
            "(50, 4, 33, 3)\n",
            "(24, 4, 32, 3)\n",
            "(15, 4, 31, 3)\n",
            "(3, 4, 30, 3)\n",
            "(72, 1, 29, 4)\n",
            "(55, 1, 28, 4)\n",
            "(14, 1, 27, 4)\n",
            "(67, -13, 26, 5)\n",
            "episode 42 score -14.0 avg score -68.1 time_steps 265 learning_steps 13\n",
            "(50, 55, 48, 0)\n",
            "(59, 55, 47, 0)\n",
            "(80, 55, 46, 0)\n",
            "(30, -25, 45, 1)\n",
            "episode 43 score -80.0 avg score -68.3 time_steps 269 learning_steps 13\n",
            "(91, 38, 48, 0)\n",
            "(94, 38, 47, 0)\n",
            "(24, 38, 46, 0)\n",
            "(70, 38, 45, 0)\n",
            "(72, 38, 44, 0)\n",
            "(3, 38, 43, 0)\n",
            "(20, 38, 42, 0)\n",
            "(27, 38, 41, 0)\n",
            "(61, 38, 40, 0)\n",
            "(61, 38, 39, 0)\n",
            "(21, 38, 38, 0)\n",
            "(6, 38, 37, 0)\n",
            "(39, 32, 36, 1)\n",
            "(46, 32, 35, 1)\n",
            "(23, -14, 34, 2)\n",
            "episode 44 score -46.0 avg score -67.8 time_steps 284 learning_steps 14\n",
            "(91, 37, 48, 1)\n",
            "(74, 37, 47, 1)\n",
            "(35, 37, 46, 1)\n",
            "(68, 37, 45, 1)\n",
            "(91, 37, 44, 1)\n",
            "(66, -54, 43, 2)\n",
            "episode 45 score -91.0 avg score -68.3 time_steps 290 learning_steps 14\n",
            "(22, 57, 48, 0)\n",
            "(43, 57, 47, 0)\n",
            "(82, 14, 46, 1)\n",
            "(49, -68, 45, 2)\n",
            "episode 46 score -82.0 avg score -68.6 time_steps 294 learning_steps 14\n",
            "(30, 55, 48, 0)\n",
            "(35, 55, 47, 0)\n",
            "(54, 20, 46, 1)\n",
            "(89, 20, 45, 1)\n",
            "(27, 20, 44, 1)\n",
            "(91, 20, 43, 1)\n",
            "(46, -71, 42, 2)\n",
            "episode 47 score -91.0 avg score -69.1 time_steps 301 learning_steps 15\n",
            "(60, 82, 48, 0)\n",
            "(99, 82, 47, 0)\n",
            "(78, -17, 46, 1)\n",
            "episode 48 score -99.0 avg score -69.7 time_steps 304 learning_steps 15\n",
            "(16, 33, 48, 0)\n",
            "(28, 33, 47, 0)\n",
            "(47, 33, 46, 0)\n",
            "(98, 33, 45, 0)\n",
            "(3, 33, 44, 0)\n",
            "(62, 33, 43, 0)\n",
            "(10, 33, 42, 0)\n",
            "(49, 33, 41, 0)\n",
            "(81, 33, 40, 0)\n",
            "(2, 33, 39, 0)\n",
            "(17, 31, 38, 1)\n",
            "(74, 31, 37, 1)\n",
            "(15, 31, 36, 1)\n",
            "(67, 31, 35, 1)\n",
            "(82, 31, 34, 1)\n",
            "(46, 31, 33, 1)\n",
            "(81, 31, 32, 1)\n",
            "(2, 31, 31, 1)\n",
            "(67, 31, 30, 1)\n",
            "(89, 31, 29, 1)\n",
            "(51, 31, 28, 1)\n",
            "(64, 31, 27, 1)\n",
            "(57, 31, 26, 1)\n",
            "(22, 31, 25, 1)\n",
            "(67, 31, 24, 1)\n",
            "(72, -36, 23, 2)\n",
            "episode 49 score -67.0 avg score -69.7 time_steps 330 learning_steps 16\n",
            "(81, -55, 48, 1)\n",
            "episode 50 score -99.0 avg score -70.2 time_steps 331 learning_steps 16\n",
            "(1, -11, 48, 1)\n",
            "episode 51 score -31.0 avg score -69.5 time_steps 332 learning_steps 16\n",
            "(2, 69, 48, 0)\n",
            "(22, 67, 47, 1)\n",
            "(98, 67, 46, 1)\n",
            "(98, -31, 45, 2)\n",
            "episode 52 score -98.0 avg score -70.0 time_steps 336 learning_steps 16\n",
            "(58, 25, 48, 0)\n",
            "(17, 25, 47, 0)\n",
            "(69, 25, 46, 0)\n",
            "(60, -44, 45, 1)\n",
            "episode 53 score -69.0 avg score -70.0 time_steps 340 learning_steps 17\n",
            "(57, 25, 48, 0)\n",
            "(86, -32, 47, 1)\n",
            "episode 54 score -57.0 avg score -69.8 time_steps 342 learning_steps 17\n",
            "(21, 49, 48, 0)\n",
            "(20, 28, 47, 1)\n",
            "(43, 8, 46, 2)\n",
            "(69, 8, 45, 2)\n",
            "(92, -61, 44, 3)\n",
            "episode 55 score -69.0 avg score -69.8 time_steps 347 learning_steps 17\n",
            "(38, 2, 48, 0)\n",
            "(74, 2, 47, 0)\n",
            "(52, 2, 46, 0)\n",
            "(60, 2, 45, 0)\n",
            "(14, 2, 44, 0)\n",
            "(54, -12, 43, 1)\n",
            "episode 56 score -14.0 avg score -68.8 time_steps 353 learning_steps 17\n",
            "(51, -6, 48, 1)\n",
            "episode 57 score -85.0 avg score -69.1 time_steps 354 learning_steps 17\n",
            "(65, 17, 48, 0)\n",
            "(23, -48, 47, 1)\n",
            "episode 58 score -65.0 avg score -69.0 time_steps 356 learning_steps 17\n",
            "(46, 25, 48, 0)\n",
            "(74, 25, 47, 0)\n",
            "(51, 25, 46, 0)\n",
            "(72, -26, 45, 1)\n",
            "episode 59 score -51.0 avg score -68.7 time_steps 360 learning_steps 18\n",
            "(54, 60, 48, 0)\n",
            "(70, 60, 47, 0)\n",
            "(33, 60, 46, 0)\n",
            "(10, 60, 45, 0)\n",
            "(14, 50, 44, 1)\n",
            "(6, 50, 43, 1)\n",
            "(30, 44, 42, 2)\n",
            "(11, 44, 41, 2)\n",
            "(13, 44, 40, 2)\n",
            "(15, 44, 39, 2)\n",
            "(19, 44, 38, 2)\n",
            "(56, 44, 37, 2)\n",
            "(70, 44, 36, 2)\n",
            "(78, 44, 35, 2)\n",
            "(96, 44, 34, 2)\n",
            "(5, 44, 33, 2)\n",
            "(50, 44, 32, 2)\n",
            "(81, -6, 31, 3)\n",
            "episode 60 score -50.0 avg score -68.4 time_steps 378 learning_steps 18\n",
            "(8, 61, 48, 0)\n",
            "(3, 61, 47, 0)\n",
            "(4, 58, 46, 1)\n",
            "(99, 58, 45, 1)\n",
            "(83, 58, 44, 1)\n",
            "(27, -25, 43, 2)\n",
            "episode 61 score -83.0 avg score -68.6 time_steps 384 learning_steps 19\n",
            "(98, 29, 48, 0)\n",
            "(93, -69, 47, 1)\n",
            "episode 62 score -98.0 avg score -69.1 time_steps 386 learning_steps 19\n",
            "(93, 81, 48, 0)\n",
            "(29, -12, 47, 1)\n",
            "episode 63 score -93.0 avg score -69.5 time_steps 388 learning_steps 19\n",
            "(8, 35, 48, 1)\n",
            "(81, 27, 47, 2)\n",
            "(64, 27, 46, 2)\n",
            "(93, 27, 45, 2)\n",
            "(97, 27, 44, 2)\n",
            "(98, 27, 43, 2)\n",
            "(52, 27, 42, 2)\n",
            "(56, 27, 41, 2)\n",
            "(71, 27, 40, 2)\n",
            "(11, 27, 39, 2)\n",
            "(6, 27, 38, 2)\n",
            "(26, 27, 37, 2)\n",
            "(89, 27, 36, 2)\n",
            "(6, 27, 35, 2)\n",
            "(3, 27, 34, 2)\n",
            "(95, 27, 33, 2)\n",
            "(15, 27, 32, 2)\n",
            "(49, 12, 31, 3)\n",
            "(99, 12, 30, 3)\n",
            "(18, 12, 29, 3)\n",
            "(96, -6, 28, 4)\n",
            "episode 64 score -18.0 avg score -68.7 time_steps 409 learning_steps 20\n",
            "(90, 13, 48, 0)\n",
            "(63, -77, 47, 1)\n",
            "episode 65 score -90.0 avg score -69.0 time_steps 411 learning_steps 20\n",
            "(88, 70, 48, 0)\n",
            "(76, 70, 47, 0)\n",
            "(93, 70, 46, 0)\n",
            "(63, 70, 45, 0)\n",
            "(53, 70, 44, 0)\n",
            "(60, 17, 43, 1)\n",
            "(61, 17, 42, 1)\n",
            "(95, -44, 41, 2)\n",
            "episode 66 score -61.0 avg score -68.9 time_steps 419 learning_steps 20\n",
            "(98, 54, 48, 1)\n",
            "(87, 54, 47, 1)\n",
            "(44, 54, 46, 1)\n",
            "(77, 54, 45, 1)\n",
            "(68, 54, 44, 1)\n",
            "(29, 54, 43, 1)\n",
            "(78, 54, 42, 1)\n",
            "(65, 54, 41, 1)\n",
            "(10, 54, 40, 1)\n",
            "(58, 54, 39, 1)\n",
            "(56, 54, 38, 1)\n",
            "(95, 54, 37, 1)\n",
            "(62, 54, 36, 1)\n",
            "(41, 54, 35, 1)\n",
            "(68, 54, 34, 1)\n",
            "(28, 54, 33, 1)\n",
            "(32, 54, 32, 1)\n",
            "(4, 22, 31, 2)\n",
            "(58, 22, 30, 2)\n",
            "(2, -36, 29, 3)\n",
            "episode 67 score -58.0 avg score -68.7 time_steps 439 learning_steps 21\n",
            "(69, 65, 48, 0)\n",
            "(41, 65, 47, 0)\n",
            "(31, 65, 46, 0)\n",
            "(1, 65, 45, 0)\n",
            "(16, 65, 44, 0)\n",
            "(42, 65, 43, 0)\n",
            "(45, 65, 42, 0)\n",
            "(24, 65, 41, 0)\n",
            "(86, 65, 40, 0)\n",
            "(75, 65, 39, 0)\n",
            "(5, 65, 38, 0)\n",
            "(73, 60, 37, 1)\n",
            "(100, -13, 36, 2)\n",
            "episode 68 score -73.0 avg score -68.8 time_steps 452 learning_steps 22\n",
            "(24, 82, 48, 0)\n",
            "(98, 82, 47, 0)\n",
            "(56, -16, 46, 1)\n",
            "episode 69 score -98.0 avg score -69.2 time_steps 455 learning_steps 22\n",
            "(8, 20, 48, 0)\n",
            "(38, 20, 47, 0)\n",
            "(85, 20, 46, 0)\n",
            "(4, -65, 45, 1)\n",
            "episode 70 score -85.0 avg score -69.4 time_steps 459 learning_steps 22\n",
            "(11, 49, 48, 0)\n",
            "(65, 49, 47, 0)\n",
            "(31, 49, 46, 0)\n",
            "(35, 49, 45, 0)\n",
            "(71, 49, 44, 0)\n",
            "(25, 49, 43, 0)\n",
            "(37, 49, 42, 0)\n",
            "(31, 49, 41, 0)\n",
            "(53, 49, 40, 0)\n",
            "(67, 49, 39, 0)\n",
            "(76, 49, 38, 0)\n",
            "(92, -27, 37, 1)\n",
            "episode 71 score -76.0 avg score -69.5 time_steps 471 learning_steps 23\n",
            "(18, 75, 48, 0)\n",
            "(37, 57, 47, 1)\n",
            "(98, 20, 46, 2)\n",
            "(72, 20, 45, 2)\n",
            "(1, -52, 44, 3)\n",
            "episode 72 score -72.0 avg score -69.5 time_steps 476 learning_steps 23\n",
            "(62, 98, 48, 0)\n",
            "(50, 98, 47, 0)\n",
            "(62, 98, 46, 0)\n",
            "(92, 98, 45, 0)\n",
            "(70, 6, 44, 1)\n",
            "(48, 6, 43, 1)\n",
            "(13, 6, 42, 1)\n",
            "(22, 6, 41, 1)\n",
            "(34, -16, 40, 2)\n",
            "episode 73 score -22.0 avg score -68.9 time_steps 485 learning_steps 24\n",
            "(43, 57, 48, 0)\n",
            "(82, 14, 47, 1)\n",
            "(100, 14, 46, 1)\n",
            "(95, 14, 45, 1)\n",
            "(7, 14, 44, 1)\n",
            "(22, 7, 43, 2)\n",
            "(9, 7, 42, 2)\n",
            "(6, 7, 41, 2)\n",
            "(75, 1, 40, 3)\n",
            "(51, -74, 39, 4)\n",
            "episode 74 score -75.0 avg score -69.0 time_steps 495 learning_steps 24\n",
            "(35, 94, 48, 0)\n",
            "(89, 59, 47, 1)\n",
            "(86, -30, 46, 2)\n",
            "episode 75 score -89.0 avg score -69.2 time_steps 498 learning_steps 24\n",
            "(49, 48, 48, 1)\n",
            "(46, -1, 47, 2)\n",
            "episode 76 score -49.0 avg score -69.0 time_steps 500 learning_steps 25\n",
            "(24, 9, 48, 0)\n",
            "(1, -15, 47, 1)\n",
            "episode 77 score -24.0 avg score -68.4 time_steps 502 learning_steps 25\n",
            "(85, 67, 48, 0)\n",
            "(53, 67, 47, 0)\n",
            "(71, 14, 46, 1)\n",
            "(91, 14, 45, 1)\n",
            "(3, 14, 44, 1)\n",
            "(15, 14, 43, 1)\n",
            "(34, 14, 42, 1)\n",
            "(8, 14, 41, 1)\n",
            "(19, 6, 40, 2)\n",
            "(84, -13, 39, 3)\n",
            "episode 78 score -19.0 avg score -67.8 time_steps 512 learning_steps 25\n",
            "(1, 7, 48, 1)\n",
            "(98, 7, 47, 1)\n",
            "(66, 7, 46, 1)\n",
            "(3, 7, 45, 1)\n",
            "(21, 7, 44, 1)\n",
            "(49, 7, 43, 1)\n",
            "(11, 7, 42, 1)\n",
            "(11, -4, 41, 2)\n",
            "episode 79 score -11.0 avg score -67.1 time_steps 520 learning_steps 26\n",
            "(3, 60, 48, 1)\n",
            "(73, 60, 47, 1)\n",
            "(97, -13, 46, 2)\n",
            "episode 80 score -73.0 avg score -67.1 time_steps 523 learning_steps 26\n",
            "(36, -41, 48, 1)\n",
            "episode 81 score -71.0 avg score -67.2 time_steps 524 learning_steps 26\n",
            "(72, 12, 48, 0)\n",
            "(56, -60, 47, 1)\n",
            "episode 82 score -72.0 avg score -67.2 time_steps 526 learning_steps 26\n",
            "(88, 62, 48, 0)\n",
            "(43, 62, 47, 0)\n",
            "(86, 62, 46, 0)\n",
            "(16, -24, 45, 1)\n",
            "episode 83 score -86.0 avg score -67.5 time_steps 530 learning_steps 26\n",
            "(19, 100, 48, 0)\n",
            "(59, 100, 47, 0)\n",
            "(15, 100, 46, 0)\n",
            "(91, 85, 45, 1)\n",
            "(71, 85, 44, 1)\n",
            "(99, 85, 43, 1)\n",
            "(81, 85, 42, 1)\n",
            "(93, 4, 41, 2)\n",
            "(88, 4, 40, 2)\n",
            "(12, -84, 39, 3)\n",
            "episode 84 score -88.0 avg score -67.7 time_steps 540 learning_steps 27\n",
            "(73, 30, 48, 0)\n",
            "(19, 30, 47, 0)\n",
            "(12, 30, 46, 0)\n",
            "(11, 30, 45, 0)\n",
            "(58, 30, 44, 0)\n",
            "(53, 30, 43, 0)\n",
            "(66, 30, 42, 0)\n",
            "(30, 30, 41, 0)\n",
            "(44, 0, 40, 1)\n",
            "... saving models ...\n",
            "episode 85 score 1000000.0 avg score 11561.0 time_steps 549 learning_steps 27\n",
            "(54, 98, 48, 0)\n",
            "(37, 44, 47, 1)\n",
            "(61, 44, 46, 1)\n",
            "(33, -17, 45, 2)\n",
            "episode 86 score -61.0 avg score 11427.4 time_steps 553 learning_steps 27\n",
            "(18, -28, 48, 1)\n",
            "episode 87 score -99.0 avg score 11296.4 time_steps 554 learning_steps 27\n",
            "(28, 30, 48, 0)\n",
            "(97, 30, 47, 0)\n",
            "(15, -67, 46, 1)\n",
            "episode 88 score -97.0 avg score 11168.4 time_steps 557 learning_steps 27\n",
            "(81, 82, 48, 0)\n",
            "(46, 82, 47, 0)\n",
            "(80, 82, 46, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(24, 82, 45, 0)\n",
            "(66, 82, 44, 0)\n",
            "(80, 82, 43, 0)\n",
            "(9, 2, 42, 1)\n",
            "(31, 2, 41, 1)\n",
            "(7, 2, 40, 1)\n",
            "(18, 2, 39, 1)\n",
            "(73, -16, 38, 2)\n",
            "episode 89 score -18.0 avg score 11044.1 time_steps 568 learning_steps 28\n",
            "(5, 30, 48, 0)\n",
            "(11, 30, 47, 0)\n",
            "(49, 30, 46, 0)\n",
            "(83, 30, 45, 0)\n",
            "(52, 30, 44, 0)\n",
            "(23, -22, 43, 1)\n",
            "episode 90 score -52.0 avg score 10922.2 time_steps 574 learning_steps 28\n",
            "(77, -53, 48, 1)\n",
            "episode 91 score -65.0 avg score 10802.8 time_steps 575 learning_steps 28\n",
            "(91, -23, 48, 1)\n",
            "episode 92 score -80.0 avg score 10685.7 time_steps 576 learning_steps 28\n",
            "(89, -21, 48, 1)\n",
            "episode 93 score -70.0 avg score 10571.3 time_steps 577 learning_steps 28\n",
            "(71, 27, 48, 0)\n",
            "(22, 27, 47, 0)\n",
            "(81, 5, 46, 1)\n",
            "(90, -76, 45, 2)\n",
            "episode 94 score -81.0 avg score 10459.2 time_steps 581 learning_steps 29\n",
            "(66, 13, 48, 0)\n",
            "(7, 13, 47, 0)\n",
            "(42, 13, 46, 0)\n",
            "(31, 13, 45, 0)\n",
            "(50, 13, 44, 0)\n",
            "(65, 13, 43, 0)\n",
            "(11, 13, 42, 0)\n",
            "(71, 13, 41, 0)\n",
            "(73, -58, 40, 1)\n",
            "episode 95 score -71.0 avg score 10349.5 time_steps 590 learning_steps 29\n",
            "(64, 20, 48, 0)\n",
            "(48, 20, 47, 0)\n",
            "(69, 20, 46, 0)\n",
            "(42, -49, 45, 1)\n",
            "episode 96 score -69.0 avg score 10242.1 time_steps 594 learning_steps 29\n",
            "(35, 22, 48, 0)\n",
            "(83, 22, 47, 0)\n",
            "(62, 22, 46, 0)\n",
            "(38, 22, 45, 0)\n",
            "(57, 22, 44, 0)\n",
            "(67, 22, 43, 0)\n",
            "(57, 22, 42, 0)\n",
            "(19, 22, 41, 0)\n",
            "(27, 22, 40, 0)\n",
            "(98, 22, 39, 0)\n",
            "(78, 22, 38, 0)\n",
            "(26, 22, 37, 0)\n",
            "(16, -4, 36, 1)\n",
            "episode 97 score -26.0 avg score 10137.3 time_steps 607 learning_steps 30\n",
            "(52, 99, 48, 0)\n",
            "(32, 47, 47, 1)\n",
            "(64, 47, 46, 1)\n",
            "(69, -17, 45, 2)\n",
            "episode 98 score -64.0 avg score 10034.3 time_steps 611 learning_steps 30\n",
            "(33, 25, 48, 0)\n",
            "(46, 25, 47, 0)\n",
            "(13, 25, 46, 0)\n",
            "(41, 25, 45, 0)\n",
            "(43, 25, 44, 0)\n",
            "(15, -18, 43, 1)\n",
            "episode 99 score -43.0 avg score 9933.5 time_steps 617 learning_steps 30\n",
            "(37, 96, 48, 0)\n",
            "(13, 96, 47, 0)\n",
            "(48, 96, 46, 0)\n",
            "(16, 48, 45, 1)\n",
            "(22, 32, 44, 2)\n",
            "(22, 10, 43, 3)\n",
            "(96, 10, 42, 3)\n",
            "(58, 10, 41, 3)\n",
            "(22, 10, 40, 3)\n",
            "(77, -12, 39, 4)\n",
            "episode 100 score -22.0 avg score 9933.7 time_steps 627 learning_steps 31\n",
            "(43, 61, 48, 0)\n",
            "(12, 61, 47, 0)\n",
            "(3, 61, 46, 0)\n",
            "(26, 61, 45, 0)\n",
            "(72, 61, 44, 0)\n",
            "(62, -11, 43, 1)\n",
            "episode 101 score -72.0 avg score 9933.5 time_steps 633 learning_steps 31\n",
            "(78, 66, 48, 1)\n",
            "(33, 66, 47, 1)\n",
            "(69, 66, 46, 1)\n",
            "(22, 66, 45, 1)\n",
            "(16, 66, 44, 1)\n",
            "(3, 50, 43, 2)\n",
            "(79, 50, 42, 2)\n",
            "(11, 50, 41, 2)\n",
            "(49, 50, 40, 2)\n",
            "(4, 1, 39, 3)\n",
            "(19, 1, 38, 3)\n",
            "(93, 1, 37, 3)\n",
            "(59, 1, 36, 3)\n",
            "(52, 1, 35, 3)\n",
            "(67, 1, 34, 3)\n",
            "(78, 1, 33, 3)\n",
            "(69, -77, 32, 4)\n",
            "episode 102 score -78.0 avg score 9933.6 time_steps 650 learning_steps 32\n",
            "(82, 43, 48, 0)\n",
            "(35, 43, 47, 0)\n",
            "(93, 43, 46, 0)\n",
            "(81, 43, 45, 0)\n",
            "(46, 43, 44, 0)\n",
            "(45, 43, 43, 0)\n",
            "(82, 43, 42, 0)\n",
            "(90, 43, 41, 0)\n",
            "(92, -47, 40, 1)\n",
            "episode 103 score -90.0 avg score 9933.1 time_steps 659 learning_steps 32\n",
            "(65, 3, 48, 0)\n",
            "(87, -62, 47, 1)\n",
            "episode 104 score -65.0 avg score 9932.6 time_steps 661 learning_steps 33\n",
            "(9, 6, 48, 0)\n",
            "(9, 6, 47, 0)\n",
            "(49, 6, 46, 0)\n",
            "(49, -43, 45, 1)\n",
            "episode 105 score -49.0 avg score 9932.6 time_steps 665 learning_steps 33\n",
            "(52, -24, 48, 1)\n",
            "episode 106 score -93.0 avg score 9932.6 time_steps 666 learning_steps 33\n",
            "(97, 27, 48, 0)\n",
            "(39, -70, 47, 1)\n",
            "episode 107 score -97.0 avg score 9932.4 time_steps 668 learning_steps 33\n",
            "(79, 55, 48, 0)\n",
            "(13, 55, 47, 0)\n",
            "(42, 55, 46, 0)\n",
            "(86, 55, 45, 0)\n",
            "(52, -31, 44, 1)\n",
            "episode 108 score -86.0 avg score 9932.4 time_steps 673 learning_steps 33\n",
            "(16, 24, 48, 0)\n",
            "(18, 24, 47, 0)\n",
            "(86, 24, 46, 0)\n",
            "(92, 24, 45, 0)\n",
            "(17, 24, 44, 0)\n",
            "(44, 24, 43, 0)\n",
            "(47, 24, 42, 0)\n",
            "(71, 24, 41, 0)\n",
            "(15, -47, 40, 1)\n",
            "episode 109 score -71.0 avg score 9932.1 time_steps 682 learning_steps 34\n",
            "(65, -18, 48, 1)\n",
            "episode 110 score -26.0 avg score 9932.8 time_steps 683 learning_steps 34\n",
            "(48, 72, 48, 0)\n",
            "(61, 24, 47, 1)\n",
            "(93, 24, 46, 1)\n",
            "(75, 24, 45, 1)\n",
            "(19, -51, 44, 2)\n",
            "episode 111 score -75.0 avg score 9932.9 time_steps 688 learning_steps 34\n",
            "(96, 75, 48, 0)\n",
            "(1, 75, 47, 0)\n",
            "(52, 75, 46, 0)\n",
            "(73, 75, 45, 0)\n",
            "(64, 75, 44, 0)\n",
            "(46, 75, 43, 0)\n",
            "(42, 75, 42, 0)\n",
            "(16, 75, 41, 0)\n",
            "(10, 59, 40, 1)\n",
            "(83, 59, 39, 1)\n",
            "(48, 59, 38, 1)\n",
            "(83, 59, 37, 1)\n",
            "(10, -24, 36, 2)\n",
            "episode 112 score -83.0 avg score 9932.9 time_steps 701 learning_steps 35\n",
            "(54, 33, 48, 0)\n",
            "(46, 33, 47, 0)\n",
            "(39, 33, 46, 0)\n",
            "(93, 33, 45, 0)\n",
            "(18, 33, 44, 0)\n",
            "(27, 33, 43, 0)\n",
            "(73, 33, 42, 0)\n",
            "(46, -40, 41, 1)\n",
            "episode 113 score -73.0 avg score 9932.9 time_steps 709 learning_steps 35\n",
            "(60, -28, 48, 1)\n",
            "episode 114 score -89.0 avg score 9932.7 time_steps 710 learning_steps 35\n",
            "(22, 37, 48, 0)\n",
            "(47, 37, 47, 0)\n",
            "(43, 37, 46, 0)\n",
            "(22, -6, 45, 1)\n",
            "episode 115 score -43.0 avg score 9932.8 time_steps 714 learning_steps 35\n",
            "(27, 83, 48, 0)\n",
            "(91, 83, 47, 0)\n",
            "(67, 83, 46, 0)\n",
            "(64, 83, 45, 0)\n",
            "(31, 83, 44, 0)\n",
            "(66, 52, 43, 1)\n",
            "(59, 52, 42, 1)\n",
            "(66, 52, 41, 1)\n",
            "(23, -14, 40, 2)\n",
            "episode 116 score -66.0 avg score 9933.1 time_steps 723 learning_steps 36\n",
            "(38, 42, 48, 0)\n",
            "(47, 42, 47, 0)\n",
            "(47, 42, 46, 0)\n",
            "(11, 42, 45, 0)\n",
            "(66, 31, 44, 1)\n",
            "(58, -35, 43, 2)\n",
            "episode 117 score -66.0 avg score 9933.3 time_steps 729 learning_steps 36\n",
            "(23, 58, 48, 1)\n",
            "(48, 58, 47, 1)\n",
            "(18, 10, 46, 2)\n",
            "(11, 10, 45, 2)\n",
            "(34, 10, 44, 2)\n",
            "(39, 10, 43, 2)\n",
            "(95, 10, 42, 2)\n",
            "(20, 10, 41, 2)\n",
            "(98, -10, 40, 3)\n",
            "episode 118 score -20.0 avg score 9933.8 time_steps 738 learning_steps 36\n",
            "(65, -50, 48, 1)\n",
            "episode 119 score -52.0 avg score 9934.1 time_steps 739 learning_steps 36\n",
            "(14, -11, 48, 1)\n",
            "episode 120 score -35.0 avg score 9934.4 time_steps 740 learning_steps 37\n",
            "(79, 40, 48, 0)\n",
            "(74, 40, 47, 0)\n",
            "(48, -34, 46, 1)\n",
            "episode 121 score -74.0 avg score 9934.4 time_steps 743 learning_steps 37\n",
            "(95, -23, 48, 1)\n",
            "episode 122 score -41.0 avg score 9934.5 time_steps 744 learning_steps 37\n",
            "(35, 35, 48, 0)\n",
            "(96, 35, 47, 0)\n",
            "(36, 35, 46, 0)\n",
            "(78, 35, 45, 0)\n",
            "(95, -43, 44, 1)\n",
            "episode 123 score -78.0 avg score 9934.6 time_steps 749 learning_steps 37\n",
            "(94, -69, 48, 1)\n",
            "episode 124 score -77.0 avg score 9934.7 time_steps 750 learning_steps 37\n",
            "(50, 19, 48, 1)\n",
            "(92, 19, 47, 1)\n",
            "(92, 19, 46, 1)\n",
            "(55, 19, 45, 1)\n",
            "(3, 19, 44, 1)\n",
            "(99, 19, 43, 1)\n",
            "(31, -80, 42, 2)\n",
            "episode 125 score -99.0 avg score 9934.4 time_steps 757 learning_steps 37\n",
            "(74, 75, 48, 0)\n",
            "(50, 75, 47, 0)\n",
            "(57, 25, 46, 1)\n",
            "(6, 25, 45, 1)\n",
            "(4, 25, 44, 1)\n",
            "(71, 21, 43, 2)\n",
            "(60, 21, 42, 2)\n",
            "(27, 21, 41, 2)\n",
            "(88, -6, 40, 3)\n",
            "episode 126 score -27.0 avg score 9935.1 time_steps 766 learning_steps 38\n",
            "(76, 39, 48, 0)\n",
            "(67, 39, 47, 0)\n",
            "(28, 39, 46, 0)\n",
            "(59, 39, 45, 0)\n",
            "(91, 39, 44, 0)\n",
            "(44, 39, 43, 0)\n",
            "(87, 39, 42, 0)\n",
            "(51, -48, 41, 1)\n",
            "episode 127 score -87.0 avg score 9934.8 time_steps 774 learning_steps 38\n",
            "(15, 76, 48, 0)\n",
            "(83, 76, 47, 0)\n",
            "(53, 76, 46, 0)\n",
            "(51, 23, 45, 1)\n",
            "(35, 23, 44, 1)\n",
            "(49, 23, 43, 1)\n",
            "(94, -26, 42, 2)\n",
            "episode 128 score -49.0 avg score 9935.3 time_steps 781 learning_steps 39\n",
            "(77, 5, 48, 0)\n",
            "(77, 5, 47, 0)\n",
            "(33, -72, 46, 1)\n",
            "episode 129 score -77.0 avg score 9935.1 time_steps 784 learning_steps 39\n",
            "(84, 57, 48, 0)\n",
            "(49, 57, 47, 0)\n",
            "(28, 57, 46, 0)\n",
            "(62, 57, 45, 0)\n",
            "(53, -5, 44, 1)\n",
            "episode 130 score -62.0 avg score 9934.6 time_steps 789 learning_steps 39\n",
            "(2, 36, 48, 1)\n",
            "(45, 36, 47, 1)\n",
            "(4, 36, 46, 1)\n",
            "(18, 36, 45, 1)\n",
            "(54, 36, 44, 1)\n",
            "(77, 36, 43, 1)\n",
            "(92, 36, 42, 1)\n",
            "(34, 36, 41, 1)\n",
            "(26, 36, 40, 1)\n",
            "(43, 36, 39, 1)\n",
            "(87, -7, 38, 2)\n",
            "episode 131 score -43.0 avg score 9934.2 time_steps 800 learning_steps 40\n",
            "(78, 74, 48, 0)\n",
            "(40, 74, 47, 0)\n",
            "(61, 74, 46, 0)\n",
            "(96, 74, 45, 0)\n",
            "(43, 74, 44, 0)\n",
            "(91, 74, 43, 0)\n",
            "(58, -17, 42, 1)\n",
            "episode 132 score -91.0 avg score 9934.2 time_steps 807 learning_steps 40\n",
            "(93, 56, 48, 1)\n",
            "(51, 56, 47, 1)\n",
            "(75, 5, 46, 2)\n",
            "(84, -70, 45, 3)\n",
            "episode 133 score -75.0 avg score 9934.2 time_steps 811 learning_steps 40\n",
            "(68, 20, 48, 0)\n",
            "(26, 20, 47, 0)\n",
            "(74, 20, 46, 0)\n",
            "(50, 20, 45, 0)\n",
            "(52, 20, 44, 0)\n",
            "(19, 20, 43, 0)\n",
            "(76, 20, 42, 0)\n",
            "(44, -56, 41, 1)\n",
            "episode 134 score -76.0 avg score 9934.5 time_steps 819 learning_steps 40\n",
            "(63, 96, 48, 0)\n",
            "(41, 96, 47, 0)\n",
            "(95, 96, 46, 0)\n",
            "(53, 1, 45, 1)\n",
            "(20, 1, 44, 1)\n",
            "(26, -19, 43, 2)\n",
            "episode 135 score -20.0 avg score 9934.5 time_steps 825 learning_steps 41\n",
            "(79, 91, 48, 0)\n",
            "(97, 12, 47, 1)\n",
            "(57, -85, 46, 2)\n",
            "episode 136 score -97.0 avg score 9934.2 time_steps 828 learning_steps 41\n",
            "(49, 32, 48, 1)\n",
            "(76, 32, 47, 1)\n",
            "(2, -44, 46, 2)\n",
            "episode 137 score -76.0 avg score 9934.2 time_steps 831 learning_steps 41\n",
            "(63, 33, 48, 0)\n",
            "(52, -30, 47, 1)\n",
            "episode 138 score -63.0 avg score 9934.5 time_steps 833 learning_steps 41\n",
            "(59, 66, 48, 0)\n",
            "(80, 66, 47, 0)\n",
            "(11, -14, 46, 1)\n",
            "episode 139 score -80.0 avg score 9934.6 time_steps 836 learning_steps 41\n",
            "(65, 61, 48, 0)\n",
            "(11, 61, 47, 0)\n",
            "(55, 61, 46, 0)\n",
            "(65, 61, 45, 0)\n",
            "(35, 61, 44, 0)\n",
            "(2, 61, 43, 0)\n",
            "(78, 61, 42, 0)\n",
            "(31, -17, 41, 1)\n",
            "episode 140 score -78.0 avg score 9934.5 time_steps 844 learning_steps 42\n",
            "(28, 51, 48, 0)\n",
            "(48, 51, 47, 0)\n",
            "(84, 51, 46, 0)\n",
            "(26, 51, 45, 0)\n",
            "(10, 25, 44, 1)\n",
            "(79, 15, 43, 2)\n",
            "(26, 15, 42, 2)\n",
            "(67, 15, 41, 2)\n",
            "(49, 15, 40, 2)\n",
            "(8, -34, 39, 3)\n",
            "episode 141 score -49.0 avg score 9934.9 time_steps 854 learning_steps 42\n",
            "(69, 79, 48, 0)\n",
            "(41, 79, 47, 0)\n",
            "(88, 79, 46, 0)\n",
            "(66, 79, 45, 0)\n",
            "(73, 79, 44, 0)\n",
            "(4, 79, 43, 0)\n",
            "(83, 79, 42, 0)\n",
            "(68, -4, 41, 1)\n",
            "episode 142 score -83.0 avg score 9934.2 time_steps 862 learning_steps 43\n",
            "(94, 7, 48, 0)\n",
            "(28, 7, 47, 0)\n",
            "(23, 7, 46, 0)\n",
            "(88, 7, 45, 0)\n",
            "(68, -81, 44, 1)\n",
            "episode 143 score -88.0 avg score 9934.1 time_steps 867 learning_steps 43\n",
            "(13, 19, 48, 0)\n",
            "(31, 6, 47, 1)\n",
            "(25, 6, 46, 1)\n",
            "(58, 6, 45, 1)\n",
            "(66, 6, 44, 1)\n",
            "(55, -60, 43, 2)\n",
            "episode 144 score -66.0 avg score 9934.0 time_steps 873 learning_steps 43\n",
            "(46, 87, 48, 0)\n",
            "(10, 87, 47, 0)\n",
            "(20, 87, 46, 0)\n",
            "(49, 67, 45, 1)\n",
            "(49, 18, 44, 2)\n",
            "(21, 18, 43, 2)\n",
            "(90, 18, 42, 2)\n",
            "(9, 18, 41, 2)\n",
            "(35, 18, 40, 2)\n",
            "(75, -17, 39, 3)\n",
            "episode 145 score -35.0 avg score 9934.5 time_steps 883 learning_steps 44\n",
            "(1, 79, 48, 0)\n",
            "(37, 79, 47, 0)\n",
            "(3, 79, 46, 0)\n",
            "(56, 79, 45, 0)\n",
            "(82, 23, 44, 1)\n",
            "(33, 23, 43, 1)\n",
            "(87, -10, 42, 2)\n",
            "episode 146 score -33.0 avg score 9935.0 time_steps 890 learning_steps 44\n",
            "(79, 64, 48, 0)\n",
            "(53, 64, 47, 0)\n",
            "(25, 64, 46, 0)\n",
            "(5, 64, 45, 0)\n",
            "(22, 59, 44, 1)\n",
            "(57, 37, 43, 2)\n",
            "(19, 37, 42, 2)\n",
            "(44, 37, 41, 2)\n",
            "(76, -7, 40, 3)\n",
            "episode 147 score -44.0 avg score 9935.5 time_steps 899 learning_steps 44\n",
            "(6, 94, 48, 0)\n",
            "(14, 94, 47, 0)\n",
            "(78, 94, 46, 0)\n",
            "(60, 94, 45, 0)\n",
            "(20, 34, 44, 1)\n",
            "(79, 34, 43, 1)\n",
            "(93, 34, 42, 1)\n",
            "(35, 34, 41, 1)\n",
            "(24, 34, 40, 1)\n",
            "(69, 34, 39, 1)\n",
            "(51, 34, 38, 1)\n",
            "(59, 34, 37, 1)\n",
            "(8, -25, 36, 2)\n",
            "episode 148 score -59.0 avg score 9935.9 time_steps 912 learning_steps 45\n",
            "(73, 43, 48, 0)\n",
            "(87, 43, 47, 0)\n",
            "(40, -44, 46, 1)\n",
            "episode 149 score -87.0 avg score 9935.7 time_steps 915 learning_steps 45\n",
            "(39, 69, 48, 0)\n",
            "(32, 69, 47, 0)\n",
            "(22, 69, 46, 0)\n",
            "(84, 47, 45, 1)\n",
            "(59, 47, 44, 1)\n",
            "(50, -12, 43, 2)\n",
            "episode 150 score -59.0 avg score 9936.1 time_steps 921 learning_steps 46\n",
            "(50, 79, 48, 1)\n",
            "(5, 29, 47, 2)\n",
            "(28, 24, 46, 3)\n",
            "(85, 24, 45, 3)\n",
            "(21, 24, 44, 3)\n",
            "(72, 24, 43, 3)\n",
            "(39, 24, 42, 3)\n",
            "(39, 24, 41, 3)\n",
            "(34, -15, 40, 4)\n",
            "episode 151 score -39.0 avg score 9936.0 time_steps 930 learning_steps 46\n",
            "(17, 76, 48, 0)\n",
            "(75, 76, 47, 0)\n",
            "(58, 76, 46, 0)\n",
            "(28, 76, 45, 0)\n",
            "(87, 76, 44, 0)\n",
            "(9, 76, 43, 0)\n",
            "(81, 76, 42, 0)\n",
            "(10, 76, 41, 0)\n",
            "(94, 76, 40, 0)\n",
            "(77, 76, 39, 0)\n",
            "(69, 76, 38, 0)\n",
            "(47, 76, 37, 0)\n",
            "(70, 76, 36, 0)\n",
            "(7, 6, 35, 1)\n",
            "(14, 6, 34, 1)\n",
            "(7, -8, 33, 2)\n",
            "episode 152 score -14.0 avg score 9936.8 time_steps 946 learning_steps 47\n",
            "(60, 52, 48, 0)\n",
            "(65, -8, 47, 1)\n",
            "episode 153 score -60.0 avg score 9936.9 time_steps 948 learning_steps 47\n",
            "(73, -57, 48, 1)\n",
            "episode 154 score -78.0 avg score 9936.7 time_steps 949 learning_steps 47\n",
            "(44, -71, 48, 1)\n",
            "episode 155 score -76.0 avg score 9936.6 time_steps 950 learning_steps 47\n",
            "(14, -11, 48, 1)\n",
            "episode 156 score -34.0 avg score 9936.4 time_steps 951 learning_steps 47\n",
            "(30, 74, 48, 0)\n",
            "(40, 74, 47, 0)\n",
            "(98, 74, 46, 0)\n",
            "(51, 74, 45, 0)\n",
            "(17, 74, 44, 0)\n",
            "(19, 74, 43, 0)\n",
            "(55, 74, 42, 0)\n",
            "(48, 74, 41, 0)\n",
            "(8, 26, 40, 1)\n",
            "(70, 26, 39, 1)\n",
            "(83, 26, 38, 1)\n",
            "(29, 26, 37, 1)\n",
            "(76, 26, 36, 1)\n",
            "(98, 26, 35, 1)\n",
            "(29, 26, 34, 1)\n",
            "(87, 26, 33, 1)\n",
            "(62, 26, 32, 1)\n",
            "(31, 26, 31, 1)\n",
            "(56, 26, 30, 1)\n",
            "(8, 26, 29, 1)\n",
            "(54, 26, 28, 1)\n",
            "(11, -28, 27, 2)\n",
            "episode 157 score -54.0 avg score 9936.8 time_steps 973 learning_steps 48\n",
            "(85, 80, 48, 1)\n",
            "(24, 80, 47, 1)\n",
            "(66, 56, 46, 2)\n",
            "(38, 56, 45, 2)\n",
            "(95, 18, 44, 3)\n",
            "(8, 18, 43, 3)\n",
            "(21, 10, 42, 4)\n",
            "(84, 10, 41, 4)\n",
            "(81, -74, 40, 5)\n",
            "episode 158 score -84.0 avg score 9936.6 time_steps 982 learning_steps 49\n",
            "(45, 7, 48, 0)\n",
            "(4, -38, 47, 1)\n",
            "episode 159 score -45.0 avg score 9936.6 time_steps 984 learning_steps 49\n",
            "(20, 56, 48, 0)\n",
            "(77, 56, 47, 0)\n",
            "(6, 56, 46, 0)\n",
            "(76, 50, 45, 1)\n",
            "(9, 50, 44, 1)\n",
            "(8, 41, 43, 2)\n",
            "(59, 41, 42, 2)\n",
            "(72, 41, 41, 2)\n",
            "(17, -31, 40, 3)\n",
            "episode 160 score -72.0 avg score 9936.4 time_steps 993 learning_steps 49\n",
            "(16, 64, 48, 0)\n",
            "(16, 64, 47, 0)\n",
            "(8, 64, 46, 0)\n",
            "(34, 64, 45, 0)\n",
            "(62, 64, 44, 0)\n",
            "(27, 64, 43, 0)\n",
            "(20, 64, 42, 0)\n",
            "(25, 64, 41, 0)\n",
            "(45, 64, 40, 0)\n",
            "(91, 19, 39, 1)\n",
            "(60, 19, 38, 1)\n",
            "(45, -41, 37, 2)\n",
            "episode 161 score -60.0 avg score 9936.6 time_steps 1005 learning_steps 50\n",
            "(78, 9, 48, 0)\n",
            "(39, -69, 47, 1)\n",
            "episode 162 score -78.0 avg score 9936.8 time_steps 1007 learning_steps 50\n",
            "(42, 83, 48, 0)\n",
            "(98, 83, 47, 0)\n",
            "(50, 83, 46, 0)\n",
            "(68, 83, 45, 0)\n",
            "(79, 83, 44, 0)\n",
            "(71, 83, 43, 0)\n",
            "(63, 83, 42, 0)\n",
            "(96, 83, 41, 0)\n",
            "(92, 83, 40, 0)\n",
            "(48, 83, 39, 0)\n",
            "(56, 35, 38, 1)\n",
            "(33, 35, 37, 1)\n",
            "(55, 35, 36, 1)\n",
            "(29, -20, 35, 2)\n",
            "episode 163 score -55.0 avg score 9937.2 time_steps 1021 learning_steps 51\n",
            "(69, 32, 48, 0)\n",
            "(45, 32, 47, 0)\n",
            "(70, -13, 46, 1)\n",
            "episode 164 score -45.0 avg score 9936.9 time_steps 1024 learning_steps 51\n",
            "(90, 84, 48, 0)\n",
            "(88, 84, 47, 0)\n",
            "(28, 84, 46, 0)\n",
            "(2, 84, 45, 0)\n",
            "(46, 82, 44, 1)\n",
            "(11, 82, 43, 1)\n",
            "(91, 82, 42, 1)\n",
            "(89, -9, 41, 2)\n",
            "episode 165 score -91.0 avg score 9936.9 time_steps 1032 learning_steps 51\n",
            "(14, 4, 48, 0)\n",
            "(71, 4, 47, 0)\n",
            "(22, 4, 46, 0)\n",
            "(18, 4, 45, 0)\n",
            "(64, 4, 44, 0)\n",
            "(73, 4, 43, 0)\n",
            "(67, 4, 42, 0)\n",
            "(90, 4, 41, 0)\n",
            "(67, 4, 40, 0)\n",
            "(56, 4, 39, 0)\n",
            "(35, 4, 38, 0)\n",
            "(70, 4, 37, 0)\n",
            "(44, 4, 36, 0)\n",
            "(1, 4, 35, 0)\n",
            "(49, 4, 34, 0)\n",
            "(7, -45, 33, 1)\n",
            "episode 166 score -49.0 avg score 9937.0 time_steps 1048 learning_steps 52\n",
            "(68, 73, 48, 0)\n",
            "(35, 73, 47, 0)\n",
            "(6, 73, 46, 0)\n",
            "(74, 67, 45, 1)\n",
            "(94, -7, 44, 2)\n",
            "episode 167 score -74.0 avg score 9936.9 time_steps 1053 learning_steps 52\n",
            "(46, 12, 48, 1)\n",
            "(3, -34, 47, 2)\n",
            "episode 168 score -46.0 avg score 9937.2 time_steps 1055 learning_steps 52\n",
            "(52, 2, 48, 1)\n",
            "(1, -50, 47, 2)\n",
            "episode 169 score -52.0 avg score 9937.6 time_steps 1057 learning_steps 52\n",
            "(86, -43, 48, 1)\n",
            "episode 170 score -96.0 avg score 9937.5 time_steps 1058 learning_steps 52\n",
            "(96, -56, 48, 1)\n",
            "episode 171 score -61.0 avg score 9937.7 time_steps 1059 learning_steps 52\n",
            "(31, 29, 48, 1)\n",
            "(30, 29, 47, 1)\n",
            "(7, 29, 46, 1)\n",
            "(3, 29, 45, 1)\n",
            "(24, 29, 44, 1)\n",
            "(71, 29, 43, 1)\n",
            "(91, -42, 42, 2)\n",
            "episode 172 score -71.0 avg score 9937.7 time_steps 1066 learning_steps 53\n",
            "(51, 100, 48, 0)\n",
            "(18, 100, 47, 0)\n",
            "(76, 100, 46, 0)\n",
            "(61, 100, 45, 0)\n",
            "(68, 100, 44, 0)\n",
            "(69, 100, 43, 0)\n",
            "(38, 31, 42, 1)\n",
            "(23, -7, 41, 2)\n",
            "episode 173 score -38.0 avg score 9937.5 time_steps 1074 learning_steps 53\n",
            "(39, 17, 48, 0)\n",
            "(23, 17, 47, 0)\n",
            "(74, 17, 46, 0)\n",
            "(52, 17, 45, 0)\n",
            "(82, 17, 44, 0)\n",
            "(34, 17, 43, 0)\n",
            "(69, 17, 42, 0)\n",
            "(94, -52, 41, 1)\n",
            "episode 174 score -69.0 avg score 9937.6 time_steps 1082 learning_steps 54\n",
            "(74, 18, 48, 0)\n",
            "(92, -56, 47, 1)\n",
            "episode 175 score -74.0 avg score 9937.7 time_steps 1084 learning_steps 54\n",
            "(55, 61, 48, 0)\n",
            "(70, 61, 47, 0)\n",
            "(57, -9, 46, 1)\n",
            "episode 176 score -70.0 avg score 9937.5 time_steps 1087 learning_steps 54\n",
            "(84, 100, 48, 0)\n",
            "(65, 100, 47, 0)\n",
            "(52, 100, 46, 0)\n",
            "(35, 100, 45, 0)\n",
            "(33, 100, 44, 0)\n",
            "(82, 67, 43, 1)\n",
            "(60, 67, 42, 1)\n",
            "(36, 67, 41, 1)\n",
            "(92, 67, 40, 1)\n",
            "(10, -25, 39, 2)\n",
            "episode 177 score -92.0 avg score 9936.8 time_steps 1097 learning_steps 54\n",
            "(20, 89, 48, 1)\n",
            "(64, 89, 47, 1)\n",
            "(17, 89, 46, 1)\n",
            "(3, 72, 45, 2)\n",
            "(94, 69, 44, 3)\n",
            "(84, 69, 43, 3)\n",
            "(2, 69, 42, 3)\n",
            "(6, 69, 41, 3)\n",
            "(67, 69, 40, 3)\n",
            "(50, 69, 39, 3)\n",
            "(78, 69, 38, 3)\n",
            "(95, -9, 37, 4)\n",
            "episode 178 score -78.0 avg score 9936.2 time_steps 1109 learning_steps 55\n",
            "(37, 68, 48, 0)\n",
            "(74, 31, 47, 1)\n",
            "(19, 31, 46, 1)\n",
            "(16, 12, 45, 2)\n",
            "(89, 12, 44, 2)\n",
            "(47, 12, 43, 2)\n",
            "(44, 12, 42, 2)\n",
            "(90, 12, 41, 2)\n",
            "(20, -78, 40, 3)\n",
            "episode 179 score -90.0 avg score 9935.5 time_steps 1118 learning_steps 55\n",
            "(52, 64, 48, 0)\n",
            "(1, 12, 47, 1)\n",
            "(41, 11, 46, 2)\n",
            "(88, 11, 45, 2)\n",
            "(13, 11, 44, 2)\n",
            "(19, -2, 43, 3)\n",
            "episode 180 score -13.0 avg score 9936.0 time_steps 1124 learning_steps 56\n",
            "(29, 2, 48, 1)\n",
            "(46, -27, 47, 2)\n",
            "episode 181 score -29.0 avg score 9936.5 time_steps 1126 learning_steps 56\n",
            "(44, 62, 48, 0)\n",
            "(37, 18, 47, 1)\n",
            "(14, 18, 46, 1)\n",
            "(66, 18, 45, 1)\n",
            "(36, 18, 44, 1)\n",
            "(62, 18, 43, 1)\n",
            "(48, 18, 42, 1)\n",
            "(11, -30, 41, 2)\n",
            "episode 182 score -48.0 avg score 9936.7 time_steps 1134 learning_steps 56\n",
            "(44, 19, 48, 0)\n",
            "(81, 19, 47, 0)\n",
            "(58, 19, 46, 0)\n",
            "(92, 19, 45, 0)\n",
            "(92, -73, 44, 1)\n",
            "episode 183 score -92.0 avg score 9936.6 time_steps 1139 learning_steps 56\n",
            "(67, 9, 48, 0)\n",
            "(20, 9, 47, 0)\n",
            "(39, -11, 46, 1)\n",
            "episode 184 score -20.0 avg score 9937.3 time_steps 1142 learning_steps 57\n",
            "(29, 14, 48, 0)\n",
            "(13, 14, 47, 0)\n",
            "(97, 1, 46, 1)\n",
            "(91, -96, 45, 2)\n",
            "episode 185 score -97.0 avg score -63.6 time_steps 1146 learning_steps 57\n",
            "(22, 31, 48, 0)\n",
            "(58, 31, 47, 0)\n",
            "(5, 31, 46, 0)\n",
            "(68, 31, 45, 0)\n",
            "(73, 31, 44, 0)\n",
            "(35, -42, 43, 1)\n",
            "episode 186 score -73.0 avg score -63.8 time_steps 1152 learning_steps 57\n",
            "(87, 98, 48, 0)\n",
            "(55, 98, 47, 0)\n",
            "(65, 43, 46, 1)\n",
            "(65, -22, 45, 2)\n",
            "episode 187 score -65.0 avg score -63.4 time_steps 1156 learning_steps 57\n",
            "(8, 94, 48, 0)\n",
            "(65, 86, 47, 1)\n",
            "(9, 86, 46, 1)\n",
            "(48, 86, 45, 1)\n",
            "(38, 86, 44, 1)\n",
            "(27, 86, 43, 1)\n",
            "(39, 86, 42, 1)\n",
            "(59, 86, 41, 1)\n",
            "(33, 86, 40, 1)\n",
            "(43, 53, 39, 2)\n",
            "(64, 53, 38, 2)\n",
            "(50, 53, 37, 2)\n",
            "(99, 53, 36, 2)\n",
            "(71, 53, 35, 2)\n",
            "(100, -18, 34, 3)\n",
            "episode 188 score -71.0 avg score -63.2 time_steps 1171 learning_steps 58\n",
            "(28, 24, 48, 1)\n",
            "(81, -4, 47, 2)\n",
            "episode 189 score -28.0 avg score -63.3 time_steps 1173 learning_steps 58\n",
            "(82, 38, 48, 0)\n",
            "(14, -44, 47, 1)\n",
            "episode 190 score -82.0 avg score -63.6 time_steps 1175 learning_steps 58\n",
            "(95, 1, 48, 0)\n",
            "(47, -94, 47, 1)\n",
            "episode 191 score -95.0 avg score -63.9 time_steps 1177 learning_steps 58\n",
            "(50, 35, 48, 0)\n",
            "(39, 35, 47, 0)\n",
            "(41, -4, 46, 1)\n",
            "episode 192 score -39.0 avg score -63.5 time_steps 1180 learning_steps 59\n",
            "(45, 83, 48, 0)\n",
            "(92, 83, 47, 0)\n",
            "(41, 83, 46, 0)\n",
            "(43, 83, 45, 0)\n",
            "(84, 83, 44, 0)\n",
            "(65, 83, 43, 0)\n",
            "(98, 83, 42, 0)\n",
            "(27, 83, 41, 0)\n",
            "(81, 83, 40, 0)\n",
            "(71, 2, 39, 1)\n",
            "(48, 2, 38, 1)\n",
            "(42, -46, 37, 2)\n",
            "episode 193 score -48.0 avg score -63.2 time_steps 1192 learning_steps 59\n",
            "(37, 6, 48, 1)\n",
            "(80, 6, 47, 1)\n",
            "(99, 6, 46, 1)\n",
            "(34, -93, 45, 2)\n",
            "episode 194 score -99.0 avg score -63.4 time_steps 1196 learning_steps 59\n",
            "(29, 28, 48, 1)\n",
            "(98, -1, 47, 2)\n",
            "episode 195 score -29.0 avg score -63.0 time_steps 1198 learning_steps 59\n",
            "(17, 46, 48, 1)\n",
            "(56, 29, 47, 2)\n",
            "(48, 29, 46, 2)\n",
            "(78, 29, 45, 2)\n",
            "(70, 29, 44, 2)\n",
            "(79, 29, 43, 2)\n",
            "(66, 29, 42, 2)\n",
            "(21, 29, 41, 2)\n",
            "(64, 8, 40, 3)\n",
            "(21, 8, 39, 3)\n",
            "(22, 8, 38, 3)\n",
            "(63, 8, 37, 3)\n",
            "(35, 8, 36, 3)\n",
            "(25, 8, 35, 3)\n",
            "(3, 8, 34, 3)\n",
            "(10, 8, 33, 3)\n",
            "(30, 8, 32, 3)\n",
            "(84, -22, 31, 4)\n",
            "episode 196 score -30.0 avg score -62.6 time_steps 1216 learning_steps 60\n",
            "(99, 24, 48, 1)\n",
            "(96, 24, 47, 1)\n",
            "(50, 24, 46, 1)\n",
            "(80, 24, 45, 1)\n",
            "(12, 24, 44, 1)\n",
            "(75, 24, 43, 1)\n",
            "(6, 24, 42, 1)\n",
            "(55, 24, 41, 1)\n",
            "(24, 24, 40, 1)\n",
            "(71, 0, 39, 2)\n",
            "episode 197 score 100029.0 avg score 938.0 time_steps 1226 learning_steps 61\n",
            "(91, 47, 48, 1)\n",
            "(15, 47, 47, 1)\n",
            "(63, 47, 46, 1)\n",
            "(95, 47, 45, 1)\n",
            "(100, 47, 44, 1)\n",
            "(12, -53, 43, 2)\n",
            "episode 198 score -100.0 avg score 937.6 time_steps 1232 learning_steps 61\n",
            "(29, -48, 48, 1)\n",
            "episode 199 score -61.0 avg score 937.4 time_steps 1233 learning_steps 61\n",
            "(21, 70, 48, 0)\n",
            "(72, 70, 47, 0)\n",
            "(12, -2, 46, 1)\n",
            "episode 200 score -72.0 avg score 936.9 time_steps 1236 learning_steps 61\n",
            "(76, 59, 48, 0)\n",
            "(56, 59, 47, 0)\n",
            "(69, 59, 46, 0)\n",
            "(14, 59, 45, 0)\n",
            "(15, 45, 44, 1)\n",
            "(100, 45, 43, 1)\n",
            "(40, 45, 42, 1)\n",
            "(97, 5, 41, 2)\n",
            "(39, 5, 40, 2)\n",
            "(46, -34, 39, 3)\n",
            "episode 201 score -39.0 avg score 937.2 time_steps 1246 learning_steps 62\n",
            "(91, 24, 48, 0)\n",
            "(39, -67, 47, 1)\n",
            "episode 202 score -91.0 avg score 937.1 time_steps 1248 learning_steps 62\n",
            "(69, 75, 48, 0)\n",
            "(6, 75, 47, 0)\n",
            "(25, 75, 46, 0)\n",
            "(32, 75, 45, 0)\n",
            "(15, 43, 44, 1)\n",
            "(34, 43, 43, 1)\n",
            "(43, 9, 42, 2)\n",
            "(15, 9, 41, 2)\n",
            "(39, 9, 40, 2)\n",
            "(14, 9, 39, 2)\n",
            "(86, -5, 38, 3)\n",
            "episode 203 score -14.0 avg score 937.9 time_steps 1259 learning_steps 62\n",
            "(20, 75, 48, 0)\n",
            "(35, 55, 47, 1)\n",
            "(27, 55, 46, 1)\n",
            "(51, 55, 45, 1)\n",
            "(87, 4, 44, 2)\n",
            "(7, 4, 43, 2)\n",
            "(23, -3, 42, 3)\n",
            "episode 204 score -7.0 avg score 938.5 time_steps 1266 learning_steps 63\n",
            "(44, 35, 48, 1)\n",
            "(49, -9, 47, 2)\n",
            "episode 205 score -44.0 avg score 938.5 time_steps 1268 learning_steps 63\n",
            "(80, 14, 48, 1)\n",
            "(87, -66, 47, 2)\n",
            "episode 206 score -80.0 avg score 938.6 time_steps 1270 learning_steps 63\n",
            "(47, 15, 48, 0)\n",
            "(88, 15, 47, 0)\n",
            "(25, 15, 46, 0)\n",
            "(56, 15, 45, 0)\n",
            "(18, -41, 44, 1)\n",
            "episode 207 score -56.0 avg score 939.0 time_steps 1275 learning_steps 63\n",
            "(2, 3, 48, 1)\n",
            "(81, 3, 47, 1)\n",
            "(94, -78, 46, 2)\n",
            "episode 208 score -81.0 avg score 939.1 time_steps 1278 learning_steps 63\n",
            "(13, 40, 48, 0)\n",
            "(68, 27, 47, 1)\n",
            "(24, 27, 46, 1)\n",
            "(50, 27, 45, 1)\n",
            "(75, 27, 44, 1)\n",
            "(41, -48, 43, 2)\n",
            "episode 209 score -75.0 avg score 939.0 time_steps 1284 learning_steps 64\n",
            "(26, -67, 48, 1)\n",
            "episode 210 score -100.0 avg score 938.3 time_steps 1285 learning_steps 64\n",
            "(7, 50, 48, 0)\n",
            "(50, 50, 47, 0)\n",
            "(35, 0, 46, 1)\n",
            "episode 211 score 1000000.0 avg score 10939.1 time_steps 1288 learning_steps 64\n",
            "(94, 48, 48, 0)\n",
            "(10, -46, 47, 1)\n",
            "episode 212 score -94.0 avg score 10939.0 time_steps 1290 learning_steps 64\n",
            "(71, 5, 48, 0)\n",
            "(18, -66, 47, 1)\n",
            "episode 213 score -71.0 avg score 10939.0 time_steps 1292 learning_steps 64\n",
            "(63, 22, 48, 0)\n",
            "(43, 22, 47, 0)\n",
            "(71, 22, 46, 0)\n",
            "(63, -49, 45, 1)\n",
            "episode 214 score -71.0 avg score 10939.1 time_steps 1296 learning_steps 64\n",
            "(51, 2, 48, 0)\n",
            "(98, 2, 47, 0)\n",
            "(18, 2, 46, 0)\n",
            "(89, -16, 45, 1)\n",
            "episode 215 score -18.0 avg score 10939.4 time_steps 1300 learning_steps 65\n",
            "(45, 5, 48, 1)\n",
            "(13, 5, 47, 1)\n",
            "(63, 5, 46, 1)\n",
            "(14, 5, 45, 1)\n",
            "(59, 5, 44, 1)\n",
            "(46, -54, 43, 2)\n",
            "episode 216 score -59.0 avg score 10939.5 time_steps 1306 learning_steps 65\n",
            "(4, 79, 48, 0)\n",
            "(27, 75, 47, 1)\n",
            "(45, 48, 46, 2)\n",
            "(7, 3, 45, 3)\n",
            "(34, 3, 44, 3)\n",
            "(41, 3, 43, 3)\n",
            "(65, 3, 42, 3)\n",
            "(82, 3, 41, 3)\n",
            "(3, 3, 40, 3)\n",
            "(31, 3, 39, 3)\n",
            "(65, 3, 38, 3)\n",
            "(60, 3, 37, 3)\n",
            "(2, -57, 36, 4)\n",
            "episode 217 score -60.0 avg score 10939.5 time_steps 1319 learning_steps 65\n",
            "(50, 47, 48, 0)\n",
            "(26, 47, 47, 0)\n",
            "(90, 47, 46, 0)\n",
            "(85, 47, 45, 0)\n",
            "(50, 47, 44, 0)\n",
            "(93, 47, 43, 0)\n",
            "(36, 47, 42, 0)\n",
            "(89, 47, 41, 0)\n",
            "(66, 47, 40, 0)\n",
            "(27, 47, 39, 0)\n",
            "(7, 47, 38, 0)\n",
            "(44, 40, 37, 1)\n",
            "(83, 40, 36, 1)\n",
            "(58, 40, 35, 1)\n",
            "(19, -18, 34, 2)\n",
            "episode 218 score -58.0 avg score 10939.1 time_steps 1334 learning_steps 66\n",
            "(63, -53, 48, 1)\n",
            "episode 219 score -93.0 avg score 10938.7 time_steps 1335 learning_steps 66\n",
            "(64, 90, 48, 0)\n",
            "(42, 26, 47, 1)\n",
            "(52, 26, 46, 1)\n",
            "(95, 26, 45, 1)\n",
            "(9, 26, 44, 1)\n",
            "(82, 17, 43, 2)\n",
            "(6, 17, 42, 2)\n",
            "(9, 11, 41, 3)\n",
            "(35, 2, 40, 4)\n",
            "(37, 2, 39, 4)\n",
            "(15, -35, 38, 5)\n",
            "episode 220 score -37.0 avg score 10938.7 time_steps 1346 learning_steps 67\n",
            "(71, 22, 48, 0)\n",
            "(37, -49, 47, 1)\n",
            "episode 221 score -71.0 avg score 10938.8 time_steps 1348 learning_steps 67\n",
            "(62, 87, 48, 0)\n",
            "(51, 25, 47, 1)\n",
            "(25, 25, 46, 1)\n",
            "(29, 0, 45, 2)\n",
            "... saving models ...\n",
            "episode 222 score 100062.0 avg score 11939.8 time_steps 1352 learning_steps 67\n",
            "(48, -37, 48, 1)\n",
            "... saving models ...\n",
            "episode 223 score -42.0 avg score 11940.1 time_steps 1353 learning_steps 67\n",
            "(84, 19, 48, 0)\n",
            "(3, -65, 47, 1)\n",
            "episode 224 score -84.0 avg score 11940.1 time_steps 1355 learning_steps 67\n",
            "(41, 1, 48, 0)\n",
            "(13, 1, 47, 0)\n",
            "(7, -12, 46, 1)\n",
            "... saving models ...\n",
            "episode 225 score -13.0 avg score 11940.9 time_steps 1358 learning_steps 67\n",
            "(19, 50, 48, 0)\n",
            "(60, 50, 47, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75, 50, 46, 0)\n",
            "(3, 50, 45, 0)\n",
            "(40, 47, 44, 1)\n",
            "(26, 47, 43, 1)\n",
            "(74, 47, 42, 1)\n",
            "(77, 47, 41, 1)\n",
            "(99, 47, 40, 1)\n",
            "(39, 47, 39, 1)\n",
            "(70, 47, 38, 1)\n",
            "(99, -23, 37, 2)\n",
            "episode 226 score -70.0 avg score 11940.5 time_steps 1370 learning_steps 68\n",
            "(45, 95, 48, 0)\n",
            "(24, 95, 47, 0)\n",
            "(76, 71, 46, 1)\n",
            "(14, 71, 45, 1)\n",
            "(83, 57, 44, 2)\n",
            "(58, -26, 43, 3)\n",
            "episode 227 score -83.0 avg score 11940.5 time_steps 1376 learning_steps 68\n",
            "(14, 53, 48, 0)\n",
            "(96, 39, 47, 1)\n",
            "(2, -57, 46, 2)\n",
            "episode 228 score -96.0 avg score 11940.1 time_steps 1379 learning_steps 68\n",
            "(62, 23, 48, 1)\n",
            "(44, 23, 47, 1)\n",
            "(77, -21, 46, 2)\n",
            "episode 229 score -44.0 avg score 11940.4 time_steps 1382 learning_steps 69\n",
            "(79, 50, 48, 0)\n",
            "(48, 50, 47, 0)\n",
            "(68, 50, 46, 0)\n",
            "(91, 50, 45, 0)\n",
            "(80, 50, 44, 0)\n",
            "(19, 50, 43, 0)\n",
            "(41, 50, 42, 0)\n",
            "(75, 9, 41, 1)\n",
            "(32, 9, 40, 1)\n",
            "(95, 9, 39, 1)\n",
            "(86, 9, 38, 1)\n",
            "(43, 9, 37, 1)\n",
            "(50, 9, 36, 1)\n",
            "(60, 9, 35, 1)\n",
            "(66, 9, 34, 1)\n",
            "(19, -57, 33, 2)\n",
            "episode 230 score -66.0 avg score 11940.4 time_steps 1398 learning_steps 69\n",
            "(69, 44, 48, 0)\n",
            "(91, 44, 47, 0)\n",
            "(70, -47, 46, 1)\n",
            "episode 231 score -91.0 avg score 11939.9 time_steps 1401 learning_steps 70\n",
            "(15, 75, 48, 0)\n",
            "(26, 75, 47, 0)\n",
            "(63, 75, 46, 0)\n",
            "(10, 12, 45, 1)\n",
            "(58, 12, 44, 1)\n",
            "(24, 12, 43, 1)\n",
            "(52, -12, 42, 2)\n",
            "episode 232 score -24.0 avg score 11940.5 time_steps 1408 learning_steps 70\n",
            "(7, 90, 48, 0)\n",
            "(5, 90, 47, 0)\n",
            "(31, 85, 46, 1)\n",
            "(80, 85, 45, 1)\n",
            "(16, 5, 44, 2)\n",
            "(85, 5, 43, 2)\n",
            "(78, 5, 42, 2)\n",
            "(77, 5, 41, 2)\n",
            "(14, -72, 40, 3)\n",
            "episode 233 score -77.0 avg score 11940.5 time_steps 1417 learning_steps 70\n",
            "(57, 34, 48, 1)\n",
            "(77, 34, 47, 1)\n",
            "(28, -43, 46, 2)\n",
            "episode 234 score -77.0 avg score 11940.5 time_steps 1420 learning_steps 71\n",
            "(14, 41, 48, 0)\n",
            "(98, 27, 47, 1)\n",
            "(1, -71, 46, 2)\n",
            "episode 235 score -98.0 avg score 11939.7 time_steps 1423 learning_steps 71\n",
            "(98, -44, 48, 1)\n",
            "episode 236 score -58.0 avg score 11940.1 time_steps 1424 learning_steps 71\n",
            "(54, -14, 48, 1)\n",
            "episode 237 score -33.0 avg score 11940.6 time_steps 1425 learning_steps 71\n",
            "(29, 69, 48, 0)\n",
            "(87, 69, 47, 0)\n",
            "(31, 69, 46, 0)\n",
            "(13, 69, 45, 0)\n",
            "(43, 69, 44, 0)\n",
            "(59, 69, 43, 0)\n",
            "(30, 69, 42, 0)\n",
            "(32, 39, 41, 1)\n",
            "(37, 39, 40, 1)\n",
            "(7, 39, 39, 1)\n",
            "(74, 39, 38, 1)\n",
            "(78, 39, 37, 1)\n",
            "(91, 39, 36, 1)\n",
            "(48, -52, 35, 2)\n",
            "episode 238 score -91.0 avg score 11940.3 time_steps 1439 learning_steps 71\n",
            "(6, 63, 48, 0)\n",
            "(93, 63, 47, 0)\n",
            "(52, 63, 46, 0)\n",
            "(29, 63, 45, 0)\n",
            "(74, 34, 44, 1)\n",
            "(29, -40, 43, 2)\n",
            "episode 239 score -74.0 avg score 11940.3 time_steps 1445 learning_steps 72\n",
            "(30, 62, 48, 0)\n",
            "(75, 32, 47, 1)\n",
            "(89, 32, 46, 1)\n",
            "(36, 32, 45, 1)\n",
            "(45, -4, 44, 2)\n",
            "episode 240 score -36.0 avg score 11940.8 time_steps 1450 learning_steps 72\n",
            "(39, 57, 48, 0)\n",
            "(82, 18, 47, 1)\n",
            "(22, 18, 46, 1)\n",
            "(62, 18, 45, 1)\n",
            "(62, -44, 44, 2)\n",
            "episode 241 score -62.0 avg score 11940.6 time_steps 1455 learning_steps 72\n",
            "(64, 54, 48, 0)\n",
            "(32, 54, 47, 0)\n",
            "(5, 22, 46, 1)\n",
            "(59, 22, 45, 1)\n",
            "(39, 22, 44, 1)\n",
            "(79, 22, 43, 1)\n",
            "(2, 22, 42, 1)\n",
            "(11, 22, 41, 1)\n",
            "(53, 11, 40, 2)\n",
            "(51, 11, 39, 2)\n",
            "(53, 11, 38, 2)\n",
            "(26, 11, 37, 2)\n",
            "(58, 11, 36, 2)\n",
            "(61, 11, 35, 2)\n",
            "(7, 11, 34, 2)\n",
            "(5, 11, 33, 2)\n",
            "(31, 11, 32, 2)\n",
            "(77, 11, 31, 2)\n",
            "(25, 11, 30, 2)\n",
            "(53, 11, 29, 2)\n",
            "(2, -42, 28, 3)\n",
            "episode 242 score -53.0 avg score 11940.9 time_steps 1476 learning_steps 73\n",
            "(51, 42, 48, 1)\n",
            "(43, 42, 47, 1)\n",
            "(85, -1, 46, 2)\n",
            "... saving models ...\n",
            "episode 243 score -43.0 avg score 11941.4 time_steps 1479 learning_steps 73\n",
            "(92, 28, 48, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(57, 28, 47, 1)\n",
            "(74, 28, 46, 1)\n",
            "(26, 28, 45, 1)\n",
            "(65, 28, 44, 1)\n",
            "(72, 28, 43, 1)\n",
            "(10, -44, 42, 2)\n",
            "episode 244 score -72.0 avg score 11941.3 time_steps 1486 learning_steps 74\n",
            "(76, -22, 48, 1)\n",
            "episode 245 score -53.0 avg score 11941.1 time_steps 1487 learning_steps 74\n",
            "(67, 73, 48, 0)\n",
            "(6, 6, 47, 1)\n",
            "(77, 0, 46, 2)\n",
            "... saving models ...\n",
            "episode 246 score 100067.0 avg score 12942.1 time_steps 1490 learning_steps 74\n",
            "(10, -29, 48, 1)\n",
            "episode 247 score -90.0 avg score 12941.7 time_steps 1491 learning_steps 74\n",
            "(72, 39, 48, 0)\n",
            "(5, 39, 47, 0)\n",
            "(96, 39, 46, 0)\n",
            "(64, -57, 45, 1)\n",
            "episode 248 score -96.0 avg score 12941.3 time_steps 1495 learning_steps 74\n",
            "(15, 39, 48, 1)\n",
            "(64, 39, 47, 1)\n",
            "(96, 39, 46, 1)\n",
            "(66, 39, 45, 1)\n",
            "(72, 39, 44, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, -33, 43, 2)\n",
            "episode 249 score -72.0 avg score 12941.5 time_steps 1501 learning_steps 75\n",
            "(86, 6, 48, 0)\n",
            "(80, 6, 47, 0)\n",
            "(8, 6, 46, 0)\n",
            "(27, 6, 45, 0)\n",
            "(2, 6, 44, 0)\n",
            "(7, 4, 43, 1)\n",
            "(30, -3, 42, 2)\n",
            "episode 250 score -7.0 avg score 12942.0 time_steps 1508 learning_steps 75\n",
            "(55, 30, 48, 0)\n",
            "(30, 30, 47, 0)\n",
            "(49, 30, 46, 0)\n",
            "(39, 30, 45, 0)\n",
            "(75, -9, 44, 1)\n",
            "episode 251 score -39.0 avg score 12942.0 time_steps 1513 learning_steps 75\n",
            "(68, 81, 48, 0)\n",
            "(64, 81, 47, 0)\n",
            "(26, 81, 46, 0)\n",
            "(47, 81, 45, 0)\n",
            "(75, 81, 44, 0)\n",
            "(35, 81, 43, 0)\n",
            "(83, 81, 42, 0)\n",
            "(84, -2, 41, 1)\n",
            "episode 252 score -83.0 avg score 12941.3 time_steps 1521 learning_steps 76\n",
            "(98, 73, 48, 1)\n",
            "(96, -25, 47, 2)\n",
            "episode 253 score -98.0 avg score 12940.9 time_steps 1523 learning_steps 76\n",
            "(33, 81, 48, 0)\n",
            "(93, 81, 47, 0)\n",
            "(71, 81, 46, 0)\n",
            "(78, 81, 45, 0)\n",
            "(73, 81, 44, 0)\n",
            "(50, 81, 43, 0)\n",
            "(71, 81, 42, 0)\n",
            "(71, 81, 41, 0)\n",
            "(34, 10, 40, 1)\n",
            "(73, 10, 39, 1)\n",
            "(16, 10, 38, 1)\n",
            "(91, -6, 37, 2)\n",
            "episode 254 score -16.0 avg score 12941.5 time_steps 1535 learning_steps 76\n",
            "(54, 3, 48, 1)\n",
            "(15, 3, 47, 1)\n",
            "(48, 3, 46, 1)\n",
            "(27, -45, 45, 2)\n",
            "episode 255 score -48.0 avg score 12941.8 time_steps 1539 learning_steps 76\n",
            "(19, 17, 48, 1)\n",
            "(74, -2, 47, 2)\n",
            "episode 256 score -19.0 avg score 12942.0 time_steps 1541 learning_steps 77\n",
            "(43, 86, 48, 0)\n",
            "(68, 86, 47, 0)\n",
            "(91, 86, 46, 0)\n",
            "(81, 86, 45, 0)\n",
            "(84, 86, 44, 0)\n",
            "(19, 86, 43, 0)\n",
            "(2, 67, 42, 1)\n",
            "(81, 67, 41, 1)\n",
            "(19, 67, 40, 1)\n",
            "(37, 48, 39, 2)\n",
            "(82, 11, 38, 3)\n",
            "(46, 11, 37, 3)\n",
            "(29, -35, 36, 4)\n",
            "episode 257 score -46.0 avg score 12942.0 time_steps 1554 learning_steps 77\n",
            "(57, 30, 48, 0)\n",
            "(33, -27, 47, 1)\n",
            "... saving models ...\n",
            "episode 258 score -57.0 avg score 12942.3 time_steps 1556 learning_steps 77\n",
            "(8, 19, 48, 0)\n",
            "(29, 19, 47, 0)\n",
            "(88, 19, 46, 0)\n",
            "(34, 19, 45, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(83, 19, 44, 0)\n",
            "(28, 19, 43, 0)\n",
            "(20, 19, 42, 0)\n",
            "(31, 19, 41, 0)\n",
            "(34, 19, 40, 0)\n",
            "(2, 19, 39, 0)\n",
            "(57, 19, 38, 0)\n",
            "(97, -38, 37, 1)\n",
            "episode 259 score -57.0 avg score 12942.2 time_steps 1568 learning_steps 78\n",
            "(71, 28, 48, 1)\n",
            "(11, 28, 47, 1)\n",
            "(22, 28, 46, 1)\n",
            "(78, 28, 45, 1)\n",
            "(50, 28, 44, 1)\n",
            "(73, 28, 43, 1)\n",
            "(72, 28, 42, 1)\n",
            "(9, 28, 41, 1)\n",
            "(81, 28, 40, 1)\n",
            "(70, 28, 39, 1)\n",
            "(84, 28, 38, 1)\n",
            "(44, 28, 37, 1)\n",
            "(64, 28, 36, 1)\n",
            "(12, 28, 35, 1)\n",
            "(32, 16, 34, 2)\n",
            "(56, 16, 33, 2)\n",
            "(69, 16, 32, 2)\n",
            "(83, -53, 31, 3)\n",
            "episode 260 score -69.0 avg score 12942.2 time_steps 1586 learning_steps 79\n",
            "(8, 8, 48, 0)\n",
            "(54, 0, 47, 1)\n",
            "... saving models ...\n",
            "episode 261 score 1000000.0 avg score 22942.8 time_steps 1588 learning_steps 79\n",
            "(4, 36, 48, 0)\n",
            "(28, 32, 47, 1)\n",
            "(78, 4, 46, 2)\n",
            "(71, -74, 45, 3)\n",
            "episode 262 score -78.0 avg score 22942.8 time_steps 1592 learning_steps 79\n",
            "(89, 63, 48, 0)\n",
            "(70, -26, 47, 1)\n",
            "episode 263 score -89.0 avg score 22942.5 time_steps 1594 learning_steps 79\n",
            "(74, 11, 48, 0)\n",
            "(60, -63, 47, 1)\n",
            "episode 264 score -74.0 avg score 22942.2 time_steps 1596 learning_steps 79\n",
            "(26, 7, 48, 1)\n",
            "(50, 7, 47, 1)\n",
            "(46, 7, 46, 1)\n",
            "(87, 7, 45, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(47, 7, 44, 1)\n",
            "(7, -40, 43, 2)\n",
            "episode 265 score -47.0 avg score 22942.6 time_steps 1602 learning_steps 80\n",
            "(66, 42, 48, 0)\n",
            "(7, 42, 47, 0)\n",
            "(14, 42, 46, 0)\n",
            "(69, 42, 45, 0)\n",
            "(97, 42, 44, 0)\n",
            "(38, 42, 43, 0)\n",
            "(32, 4, 42, 1)\n",
            "(53, 4, 41, 1)\n",
            "(20, 4, 40, 1)\n",
            "(49, 4, 39, 1)\n",
            "(89, -45, 38, 2)\n",
            "episode 266 score -49.0 avg score 22942.6 time_steps 1613 learning_steps 80\n",
            "(78, 44, 48, 1)\n",
            "(46, 44, 47, 1)\n",
            "(52, 44, 46, 1)\n",
            "(62, 44, 45, 1)\n",
            "(47, 44, 44, 1)\n",
            "(39, 44, 43, 1)\n",
            "(87, 44, 42, 1)\n",
            "(78, 44, 41, 1)\n",
            "(23, 44, 40, 1)\n",
            "(27, 44, 39, 1)\n",
            "(11, 44, 38, 1)\n",
            "(29, 44, 37, 1)\n",
            "(45, 15, 36, 2)\n",
            "(76, -30, 35, 3)\n",
            "... saving models ...\n",
            "episode 267 score -45.0 avg score 22942.9 time_steps 1627 learning_steps 81\n",
            "(37, 9, 48, 0)\n",
            "(9, 9, 47, 0)\n",
            "(97, 9, 46, 0)\n",
            "(60, 9, 45, 0)\n",
            "(66, 9, 44, 0)\n",
            "(78, -57, 43, 1)\n",
            "episode 268 score -66.0 avg score 22942.7 time_steps 1633 learning_steps 81\n",
            "(64, 36, 48, 0)\n",
            "(65, 36, 47, 0)\n",
            "(16, 36, 46, 0)\n",
            "(31, 20, 45, 1)\n",
            "(66, -11, 44, 2)\n",
            "... saving models ...\n",
            "episode 269 score -31.0 avg score 22942.9 time_steps 1638 learning_steps 81\n",
            "(75, 46, 48, 0)\n",
            "(35, 46, 47, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 46, 46, 0)\n",
            "(91, 14, 45, 1)\n",
            "(32, 14, 44, 1)\n",
            "(52, 14, 43, 1)\n",
            "(92, 14, 42, 1)\n",
            "(60, -78, 41, 2)\n",
            "... saving models ...\n",
            "episode 270 score -92.0 avg score 22943.0 time_steps 1646 learning_steps 82\n",
            "(47, 97, 48, 0)\n",
            "(10, 97, 47, 0)\n",
            "(25, 97, 46, 0)\n",
            "(99, 97, 45, 0)\n",
            "(73, 97, 44, 0)\n",
            "(8, 24, 43, 1)\n",
            "(79, 24, 42, 1)\n",
            "(54, -55, 41, 2)\n",
            "episode 271 score -79.0 avg score 22942.8 time_steps 1654 learning_steps 82\n",
            "(74, 35, 48, 0)\n",
            "(58, 35, 47, 0)\n",
            "(73, 35, 46, 0)\n",
            "(70, 35, 45, 0)\n",
            "(14, -35, 44, 1)\n",
            "episode 272 score -70.0 avg score 22942.8 time_steps 1659 learning_steps 82\n",
            "(73, 74, 48, 0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-1d695b4dcd66>:61: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  advantage[t] = a_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60, 74, 47, 0)\n",
            "(31, 14, 46, 1)\n",
            "(21, 14, 45, 1)\n",
            "(50, 14, 44, 1)\n",
            "(1, 14, 43, 1)\n",
            "(68, 14, 42, 1)\n",
            "(99, 14, 41, 1)\n",
            "(45, -85, 40, 2)\n",
            "episode 273 score -99.0 avg score 22942.2 time_steps 1668 learning_steps 83\n",
            "(75, 82, 48, 0)\n",
            "(95, 7, 47, 1)\n",
            "(33, 7, 46, 1)\n",
            "(33, 7, 45, 1)\n",
            "(16, 7, 44, 1)\n",
            "(23, 7, 43, 1)\n",
            "(24, 7, 42, 1)\n",
            "(22, 7, 41, 1)\n",
            "(42, 7, 40, 1)\n",
            "(87, 7, 39, 1)\n",
            "(40, 7, 38, 1)\n",
            "(89, -33, 37, 2)\n",
            "episode 274 score -40.0 avg score 22942.5 time_steps 1680 learning_steps 84\n",
            "(92, 88, 48, 0)\n",
            "(76, -4, 47, 1)\n",
            "episode 275 score -92.0 avg score 22942.3 time_steps 1682 learning_steps 84\n",
            "(100, -57, 48, 1)\n",
            "episode 276 score -60.0 avg score 22942.4 time_steps 1683 learning_steps 84\n",
            "(38, 79, 48, 0)\n",
            "(99, 41, 47, 1)\n",
            "(99, 41, 46, 1)\n",
            "(71, 41, 45, 1)\n",
            "(96, 41, 44, 1)\n",
            "(55, 41, 43, 1)\n",
            "(88, 41, 42, 1)\n",
            "(52, -47, 41, 2)\n",
            "episode 277 score -88.0 avg score 22942.4 time_steps 1691 learning_steps 84\n",
            "(27, 7, 48, 1)\n",
            "(80, -20, 47, 2)\n",
            "episode 278 score -27.0 avg score 22943.0 time_steps 1693 learning_steps 84\n",
            "(72, 91, 48, 0)\n",
            "(47, 91, 47, 0)\n",
            "(20, 91, 46, 0)\n",
            "(55, 91, 45, 0)\n",
            "(40, 36, 44, 1)\n",
            "(77, 36, 43, 1)\n",
            "(48, 36, 42, 1)\n",
            "(45, 36, 41, 1)\n",
            "(75, 36, 40, 1)\n",
            "(33, 36, 39, 1)\n",
            "(93, 3, 38, 2)\n",
            "(71, -90, 37, 3)\n",
            "episode 279 score -93.0 avg score 22942.9 time_steps 1705 learning_steps 85\n",
            "(48, 8, 48, 1)\n",
            "(48, 8, 47, 1)\n",
            "(71, -40, 46, 2)\n",
            "episode 280 score -48.0 avg score 22942.6 time_steps 1708 learning_steps 85\n",
            "(6, 99, 48, 0)\n",
            "(22, 99, 47, 0)\n",
            "(32, 99, 46, 0)\n",
            "(62, 99, 45, 0)\n",
            "(28, 99, 44, 0)\n",
            "(53, 71, 43, 1)\n",
            "(5, 71, 42, 1)\n",
            "(9, 71, 41, 1)\n",
            "(9, 71, 40, 1)\n",
            "(91, 71, 39, 1)\n",
            "(26, 71, 38, 1)\n",
            "(55, 71, 37, 1)\n",
            "(94, 16, 36, 2)\n",
            "(10, 16, 35, 2)\n",
            "(60, 6, 34, 3)\n",
            "(8, 6, 33, 3)\n",
            "(42, 6, 32, 3)\n",
            "(93, 6, 31, 3)\n",
            "(77, 6, 30, 3)\n",
            "(19, 6, 29, 3)\n",
            "(9, 6, 28, 3)\n",
            "(65, -3, 27, 4)\n",
            "episode 281 score -9.0 avg score 22942.8 time_steps 1730 learning_steps 86\n",
            "(58, 6, 48, 0)\n",
            "(24, 6, 47, 0)\n",
            "(95, 6, 46, 0)\n",
            "(79, 6, 45, 0)\n",
            "(73, 6, 44, 0)\n",
            "(13, 6, 43, 0)\n",
            "(74, 6, 42, 0)\n",
            "(89, 6, 41, 0)\n",
            "(63, 6, 40, 0)\n",
            "(65, 6, 39, 0)\n",
            "(4, -59, 38, 1)\n",
            "episode 282 score -65.0 avg score 22942.6 time_steps 1741 learning_steps 87\n",
            "(85, 9, 48, 0)\n",
            "(85, -76, 47, 1)\n",
            "episode 283 score -85.0 avg score 22942.7 time_steps 1743 learning_steps 87\n",
            "(2, 16, 48, 0)\n",
            "(52, 14, 47, 1)\n",
            "(54, 14, 46, 1)\n",
            "(61, -40, 45, 2)\n",
            "episode 284 score -54.0 avg score 22942.3 time_steps 1747 learning_steps 87\n",
            "(53, 61, 48, 0)\n",
            "(98, 61, 47, 0)\n",
            "(57, 61, 46, 0)\n",
            "(52, 61, 45, 0)\n",
            "(8, 61, 44, 0)\n",
            "(13, 61, 43, 0)\n",
            "(100, 48, 42, 1)\n",
            "(52, 48, 41, 1)\n",
            "(68, 48, 40, 1)\n",
            "(18, -20, 39, 2)\n",
            "episode 285 score -68.0 avg score 22942.6 time_steps 1757 learning_steps 87\n",
            "(81, 45, 48, 0)\n",
            "(21, 45, 47, 0)\n",
            "(80, 24, 46, 1)\n",
            "(85, -56, 45, 2)\n",
            "episode 286 score -80.0 avg score 22942.5 time_steps 1761 learning_steps 88\n",
            "(36, 27, 48, 0)\n",
            "(27, 27, 47, 0)\n",
            "(72, 27, 46, 0)\n",
            "(48, 27, 45, 0)\n",
            "(84, -21, 44, 1)\n",
            "episode 287 score -48.0 avg score 22942.7 time_steps 1766 learning_steps 88\n",
            "(90, -48, 48, 1)\n",
            "episode 288 score -89.0 avg score 22942.5 time_steps 1767 learning_steps 88\n",
            "(89, 72, 48, 0)\n",
            "(95, -17, 47, 1)\n",
            "episode 289 score -89.0 avg score 22941.9 time_steps 1769 learning_steps 88\n",
            "(54, 40, 48, 0)\n",
            "(51, 40, 47, 0)\n",
            "(9, 40, 46, 0)\n",
            "(86, 40, 45, 0)\n",
            "(65, -46, 44, 1)\n",
            "episode 290 score -86.0 avg score 22941.9 time_steps 1774 learning_steps 88\n",
            "(55, 45, 48, 0)\n",
            "(89, -10, 47, 1)\n",
            "episode 291 score -55.0 avg score 22942.3 time_steps 1776 learning_steps 88\n",
            "(38, 14, 48, 0)\n",
            "(100, 14, 47, 0)\n",
            "(25, 14, 46, 0)\n",
            "(32, 14, 45, 0)\n",
            "(74, 14, 44, 0)\n",
            "(13, 14, 43, 0)\n",
            "(14, 14, 42, 0)\n",
            "(73, 14, 41, 0)\n",
            "(14, -59, 40, 1)\n",
            "episode 292 score -73.0 avg score 22942.0 time_steps 1785 learning_steps 89\n",
            "(72, 53, 48, 0)\n",
            "(2, 53, 47, 0)\n",
            "(45, 53, 46, 0)\n",
            "(52, 53, 45, 0)\n",
            "(84, 53, 44, 0)\n",
            "(83, 53, 43, 0)\n",
            "(80, 53, 42, 0)\n",
            "(44, -27, 41, 1)\n",
            "episode 293 score -80.0 avg score 22941.6 time_steps 1793 learning_steps 89\n",
            "(36, 66, 48, 0)\n",
            "(15, 30, 47, 1)\n",
            "(60, 30, 46, 1)\n",
            "(87, 30, 45, 1)\n",
            "(1, 30, 44, 1)\n",
            "(88, 30, 43, 1)\n",
            "(95, 30, 42, 1)\n",
            "(4, 30, 41, 1)\n",
            "(39, 30, 40, 1)\n",
            "(7, 30, 39, 1)\n",
            "(4, 30, 38, 1)\n",
            "(37, 26, 37, 2)\n",
            "(7, 26, 36, 2)\n",
            "(86, 26, 35, 2)\n",
            "(79, -60, 34, 3)\n",
            "episode 294 score -86.0 avg score 22941.8 time_steps 1808 learning_steps 90\n",
            "(26, 20, 48, 0)\n",
            "(100, 20, 47, 0)\n",
            "(15, -80, 46, 1)\n",
            "episode 295 score -100.0 avg score 22941.0 time_steps 1811 learning_steps 90\n",
            "(84, 100, 48, 0)\n",
            "(20, 16, 47, 1)\n",
            "(92, 16, 46, 1)\n",
            "(90, -76, 45, 2)\n",
            "episode 296 score -92.0 avg score 22940.4 time_steps 1815 learning_steps 90\n",
            "(54, 83, 48, 0)\n",
            "(3, 83, 47, 0)\n",
            "(6, 83, 46, 0)\n",
            "(26, 83, 45, 0)\n",
            "(12, 57, 44, 1)\n",
            "(79, 57, 43, 1)\n",
            "(17, -22, 42, 2)\n",
            "episode 297 score -79.0 avg score 21939.3 time_steps 1822 learning_steps 91\n",
            "(1, 92, 48, 0)\n",
            "(59, 92, 47, 0)\n",
            "(44, 92, 46, 0)\n",
            "(82, 92, 45, 0)\n",
            "(59, 92, 44, 0)\n",
            "(94, 33, 43, 1)\n",
            "(99, -61, 42, 2)\n",
            "episode 298 score -94.0 avg score 21939.4 time_steps 1829 learning_steps 91\n",
            "(92, 51, 48, 0)\n",
            "(24, 51, 47, 0)\n",
            "(6, 51, 46, 0)\n",
            "(8, 51, 45, 0)\n",
            "(72, 51, 44, 0)\n",
            "(52, -21, 43, 1)\n",
            "episode 299 score -72.0 avg score 21939.3 time_steps 1835 learning_steps 91\n"
          ]
        }
      ],
      "source": [
        "N = 20\n",
        "batch_size = 5\n",
        "n_epochs = 4\n",
        "alpha = 0.0003\n",
        "# agent = Agent(n_actions=3, batch_size=batch_size,\n",
        "#               alpha=alpha, n_epochs=n_epochs,\n",
        "#               input_dims=env.observation_space.shape)\n",
        "n_games = 300\n",
        "\n",
        "best_score = 0\n",
        "score_history = []\n",
        "\n",
        "learn_iters = 0\n",
        "avg_score = 0\n",
        "n_steps = 0\n",
        "\n",
        "for i in range(n_games):\n",
        "    observation = env.reset()\n",
        "    done = False\n",
        "    score = 0\n",
        "    while not done:\n",
        "        action, prob, val = agent.choose_action(np.expand_dims(observation, axis=0))\n",
        "        observation_, reward, done, info = env.step(action)\n",
        "        n_steps += 1\n",
        "        score += reward\n",
        "        agent.store_transition(observation, action,\n",
        "                                prob, val, reward, done)\n",
        "        if n_steps % N == 0:\n",
        "            agent.learn()\n",
        "            learn_iters += 1\n",
        "        observation = observation_\n",
        "    score_history.append(score)\n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "        agent.save_models()\n",
        "    tf.summary.scalar('reward summary', data=avg_score, step=i)\n",
        "    print('episode', i, 'score %.1f' % score, 'avg score %.1f' % avg_score,\n",
        "          'time_steps', n_steps, 'learning_steps', learn_iters)\n",
        "    # env.render()\n",
        "# filename = 'PPO_trading_view.png'\n",
        "# x = [i+1 for i in range(len(score_history))]\n",
        "# plot_learning_curve(x, score_history, figure_file)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}